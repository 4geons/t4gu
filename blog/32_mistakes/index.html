<!doctype html><html lang=en data-mode=dark>
<head prefix="og: http://ogp.me/ns#">
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta name=generator content="Hugo 0.92.2">
<meta name=theme content="Color Your World -- gitlab.com/rmaguiar/hugo-theme-color-your-world">
<title>Making Misteaks</title>
<meta name=author content="Bijou M. Smith">
<meta name=robots content="index follow">
<link rel=canonical href=https://t4gu.gitlab.io/t4gu/blog/32_mistakes/>
<meta property="og:site_name" content="Topological 4-Geon Theory Unchained">
<meta property="og:title" content="Making Misteaks">
<meta property="og:url" content="https://t4gu.gitlab.io/t4gu/blog/32_mistakes/">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2023-05-19">
<meta property="article:modified_time" content="2023-05-19">
<meta property="og:updated_time" content="2023-05-19">
<meta name=twitter:dnt content="on">
<meta name=theme-color content="#222">
<meta name=apple-mobile-web-app-capable content="yes">
<meta name=apple-mobile-web-app-status-bar-style content="default">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebSite","@id":"https://t4gu.gitlab.io/t4gu"},"headline":"Making Misteaks","description":"","url":"https://t4gu.gitlab.io/t4gu/blog/32_mistakes/","inLanguage":"en","datePublished":"2023-05-19","dateModified":"2023-05-19","wordCount":"3372","publisher":{"@type":"Person","name":"Bijou M. Smith"},"author":{"@type":"Person","name":"Bijou M. Smith","description":"Random mathematician."}}</script>
<link rel=stylesheet href=https://t4gu.gitlab.io/t4gu/css/main.min.d33233e3d0eb633ea1fbb9e17553fe7c8ff07875b91d8186e046a48480987c8e.css integrity="sha256-0zIz49DrYz6h+7nhdVP+fI/weHW5HYGG4EakhICYfI4=" crossorigin=anonymous>
<noscript>
<meta name=theme-color content="#26A269">
<link rel=stylesheet href=https://t4gu.gitlab.io/t4gu/css/noscript.min.503f912ad7e7391597c629c1f7134b77fa61b200f7425671b8fbbe91f62ad657.css integrity="sha256-UD+RKtfnORWXxinB9xNLd/phsgD3QlZxuPu+kfYq1lc=" crossorigin=anonymous>
</noscript>
<link rel=preload href=/t4gu/fonts/OpenSans-Bold.ttf as=font crossorigin=anonymous>
<link rel=preload href=/t4gu/fonts/OpenSans-Italic.ttf as=font crossorigin=anonymous>
<link rel=preload href=/t4gu/fonts/OpenSans-Regular.ttf as=font crossorigin=anonymous>
<link rel=preload href=/t4gu/fonts/Oswald-Bold.ttf as=font crossorigin=anonymous>
<link rel=preload href=/libs/katex@0.16.0/dist/fonts/KaTeX_Main-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous>
<link rel=preload href=/libs/katex@0.16.0/dist/fonts/KaTeX_Math-Italic.woff2 as=font type=font/woff2 crossorigin=anonymous>
<link rel=preload href=/libs/katex@0.16.0/dist/fonts/KaTeX_Size2-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous>
<link rel=preload href=/libs/katex@0.16.0/dist/fonts/KaTeX_Size4-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous>
<script src=https://t4gu.gitlab.io/t4gu/js/main.42b683201e75d61e0c2793a3814a2306fd1f036cf6dd7f9ea3b61cd13f2d752e.js integrity="sha256-QraDIB511h4MJ5OjgUojBv0fA2z23X+eo7Yc0T8tdS4=" crossorigin=anonymous></script>
</head>
<body>
<header>
<a href=/t4gu> <img src=https://t4gu.gitlab.io/t4gu/images/t4gu_logo.svg alt="T4GU logo" style=display:flex;width:40px;height:34px;float:left;margin-bottom:-2.5px;margin-right:10px> </a>
<a href=/t4gu> Topological 4-Geon Theory Unchained </a>
<nav aria-label="Main menu.">
<ul>
<li>
<a class=btn href=/t4gu/t4gu/>Home</a>
</li>
<li>
<a class=btn href=/t4gu/t4gu/philosophy/>Philosophy</a>
</li>
<li>
<a class=btn href=/t4gu/t4gu/theory/>Theory</a>
</li>
<li>
<a class=btn href=/t4gu/t4gu/blog/>Posts</a>
</li>
<li>
<a class=btn href=/t4gu/t4gu/contact/>Contact</a>
</li>
<li>
<a class=btn href=/t4gu/t4gu/donations/>Donate</a>
</li>
</ul>
</nav>
</header>
<div class=filler>
<main>
<article>
<header>
<h1>Making Misteaks</h1>
<p>
Published on <time datetime=2023-05-19>2023-05-19</time>
</p>
</header>
<details class=toc open>
<summary class=outline-dashed>
Contents
</summary>
<nav id=TableOfContents>
<ul>
<li><a href=#ai--guns>AI = Guns</a></li>
<li><a href=#keeping-up-with-the-ai-policy>Keeping Up with the AI Policy</a></li>
<li><a href=#the-science-versus-the-engineering>The Science versus the Engineering</a>
<ul>
<li><a href=#engineering-versus-politics>Engineering versus Politics</a></li>
</ul>
</li>
<li><a href=#scrap-notes>Scrap Notes</a></li>
<li><a href=#caveats>Caveats</a></li>
</ul>
</nav>
</details>
<p>Yes, yes, I know, &ldquo;Not another AI post!&rdquo; It&rsquo;s the zeitgeist making me do it yo'.</p>
<p>Seriously though, it is nice and chill to listen to Radiohead and write these
articles no one is reading on the current AI flurry of generative tools and
fear & panic. I do not write as a contrarian for the sake of it, I have a clear
moral purpose in philosophising against the grain of almost all of AI academia and
tech-utopia activism.</p>
<p><a href="https://www.youtube.com/watch?v=O8GUH0_htRM" target=_blank>Mr AI Explained</a>
gave a very good
quick but fairly comprehensive run-down of the current GPT-4 capabilities
<a href="https://www.youtube.com/watch?v=O8GUH0_htRM" target=_blank>here</a>
.
This is what I will be using (only as background) today for a bit of on-going
critique of the AI industry.</p>
<p>As chatGPT has often pointed out, &ldquo;It&rsquo;s not the AI that is your problem, it is the
people abusing it.&rdquo;</p>
<h2 id=ai--guns><a class=anchor href=#ai--guns title="Anchor for: AI = Guns."><svg aria-hidden="true"><use xlink:href="/t4gu/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a> AI = Guns</h2>
<p>Well, ok, I do not like the &ldquo;It&rsquo;s not the guns killing people, it is people,&rdquo;
argument in the USA for 2nd Amendment &ldquo;rights&rdquo;. But it is formally similar to the
AI shill activism in favour of going full accelerationist on AI technology.</p>
<p>The story is, AI will free people up from hard labour and whatnot. But this is a
dream. AI can get rid of a lot of managerial jobs, but digging ditches takes actual
robots, which are bloody expensive (in <strong><em>real</em></strong> terms), and human labour probably
will have a cost advantage (in <strong><em>real</em></strong> terms) for a long time to come for a lot
of blue collar and cutting edge science work.</p>
<p>Try telling a CERN physicist or engineer a robot can replace their jobs. (Tip:
wear some face cheek mask protection, and a jockstrap.)</p>
<p>While you are at it, try telling a politician a robot can take their job!
That&rsquo;s the human job that&rsquo;ll never go away, simply because politicians control
the Law. Politicians, especially the lazy ones, will be heavy users of AI, but
they will never vote themselves (or the lobby industry) out of a job.</p>
<p>Why would they? Say AI does 90% of their work, they still pay themselves and their
human interns chunky salaries to do basic sanity checks, and spend most of their
time on the golf course or tennis courts, or the better politicians more time in their
electorate talking to people, since the fund raising is either now fully public
funded (MMT you dogs! No tax pay for) or at least fully automated. Pretty basic
realpolitik. You hardly need a crystal ball to see this.</p>
<p>I love the prospect of this, because the blatancy of their own job and butt
protection will be clear as day, and they will be virtually powerless to deny full
employment policy, not only a Job Guarantee MMT style, but expanded public sector
hiring for public purpose. The hypocrisy level will just be too cosmic for
politicians to avoid implementing a JG and expanded non-bullsh*t job public sector.</p>
<p>Does that make me an AI accelerationalist? I think a qualified <em>yes</em>. Full Accelerationism is gross (too many lives at stake), but in limited domains it can
be incredibly good, when no one has to die or needlessly suffer from it.</p>
<p>Anyway, so what is it, are AI&rsquo;s the new &ldquo;Guns&rdquo; here?</p>
<p>No. There is a qualitative difference. Guns are ostensibly for self-defence,
or murder. Like the other &ldquo;death devices&rdquo; the automobiles, AI is not intended
for increasing human suffering at all, the exact opposite. A lot of basic moral
political philosophy hinges on intent. Especially everyday morality. But even the
unordinary. The infamous Trolley Problem has only one solution, you save the most
people, and should not worry about retribution or unknowns, if you start worrying
about unknowns you become immoral when immediate action one way or the other is
demanded. Inaction is an action here. Once you have thought about the Inaction
option, it&rsquo;s too late to avoid moral culpability.</p>
<p>But like nuclear power, any sufficiently powerful technology can be used to increase
human suffering. You cannot allow a free market to go there. Governments are
supposed to be <strong><em>our</em></strong> representatives, not representatives of the oligarchs, so we
have to f-cking well start <em>demanding</em> some basic public protections, which means,
among many other things, exterminating all the neoliberals (by intellectual educative
means of course).</p>
<p>But if you are a rabid right-wing gun enthusiast and true believer in the
perverted form of the 2nd Amendment (any militia is a good militia), how about
acknowledging your government is in violation of your Constitution by failing to
protect the public purpose? So you aught to be also demanding extermination of the
neoliberals. Take your &ldquo;well-formed militia&rdquo; to the Capitol (again, but maybe with a
legitimate cause this time?). See how it goes.</p>
<p>I think it will not go well for you. But if you are true to your principles you
are all chicken sh*t for not trying (again). Show some cahones gdamnit.</p>
<h2 id=keeping-up-with-the-ai-policy><a class=anchor href=#keeping-up-with-the-ai-policy title="Anchor for: Keeping Up with the AI Policy."><svg aria-hidden="true"><use xlink:href="/t4gu/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a> Keeping Up with the AI Policy</h2>
<p>If you are a non-techie and want to track more general AI and tech optimism I&rsquo;d
recommend
<a href="https://www.youtube.com/watch?v=bS57Z6-dEKU&pp=ygUHZ29kYSBnbw%3D%3D" target=_blank>Goda Go</a>
.
Goda is also good on privacy issues and warning about fraud and so forth, see the
emerging <a href="https://www.youtube.com/watch?v=bS57Z6-dEKU" target=_blank>AI scam industry clip here</a>
.
Although one thing Goda and almost all AI boosting youtubers fail totally on is social
justice and the capitalization of what <em>needs</em> to be a public good in the public
commons (namely AI assistant tech).</p>
<p>((They also mostly fail, even Goda, on protecting their own software freedoms, which
since they <em>could</em> all be using GNU+Linux and no javascript in the browser they
have no excuses for their freedoms being self-violated.))</p>
<p>(((Tip: if you must use one of the javascripted ai web bots, please do it on a
sandboxed computer, preferably a virtual machine. If you are not a techie, check
your local public library &mdash; if they are not permitting the ai websites through
then probably you should not either. )))</p>
<p>We can have these private companies that get billions in government subsidies to
afford to release the tech they develop for public use (they get public transport
for their workforce, just to name a trivial massive support for firms, and don&rsquo;t
forget stock markets are supported by government regulations that prevent oodles of
fraud and scam). If you live in the USA or Russia, or other oligopolies, I can
understand you do not see the public benefits of government subsidies for
corporations, but they are there, in super-abundance. Just ask chatGPT!</p>
<p>Governments need not grab the tech off the private tech firms. The tech firms enjoy
Limited Liability protections under state law, so really should be required to cede
something to the public! The private corporations can always be paid fair market
prices for their tech to be opened to public use. Governments cannot run out of their
own currency, and if the price is not a bidding war with other private users, then
there is no inflation pressure. The tech firms just get paid, as they should, for
producing cool things.</p>
<p>&ldquo;What about the competitive and profit incentive to innovate?&rdquo; you might say.
I say to hell with that. Schumpeter got the macro analysis of creative destruction
about right, but not the class dynamics. You do not need to give a scientist or
artist financial incentive, because for a gifted scientist the reward of discovery
and invention is sufficient (I know from experience &mdash; yeah, that&rsquo;s right, I am
&ldquo;gifted&rdquo; (level 3 gifted ok)), provided they can put food on the table and pay the
rent, save a bit for retirement if they desire. Name one capitalist pig who ever
invented anything useful?</p>
<p>It&rsquo;s not those reaping the profits who are the creatives. The profit motive does
not function like you Tory bastards think.</p>
<p>One <em>reason</em> AI technology has to be open to the public is a justice issue, not a
market competition issue. But even if you are a hyper-competition free market bro,
opening the monopoly on AI tech to the public should be what you want. Governments are
improving free market forces when they regulate to require monopolies to open up their
tech.</p>
<p>The other reason is that some goods should just not be for sale. Like air we breath,
clean water, basic education, and so on and so forth (at some point what goods should
be in the public commons becomes a cultural democracy matter to debate, but a few
basics for survival are not up for debate).</p>
<p>The government need not interfere in private research competition, but the government
can always be the monopsony buyer for the output, provided the demos agrees the output
is too powerful to be sold in the market, where those with unearned or undue
purchasing power can dominate demand. Internet service is not even correctly
democratized yet, so I have zero hope short-term for democratization of AI
technology. But eventually it has to happen if we do not want a grossly unequal
society with accelerated Pareto distribution effects (the rich get richer, the poor
get poorer <em>in relative terms</em>).</p>
<p>The poor get richer of course, generally, but that is not a fair rationale for
unfettered free markets. We have to, as a decent society not be beholden to
darwinistic forces, take into account fair distribution. The market is incapable
of determining how much sweat and stress any particular worker has to suffer. A
janitor who has not the privilege of pushing buttons on cleaning robots is arguably
sacrificing more than a top CEO or CFO, and so must be given a commensurate wage.
This is not presently happening, and it is an epic tragedy.</p>
<p>(See <a href="https://youtu.be/qtfG1dM8C-U?t=819" target=_blank>Georg Rockall-Schmidt</a>
on the value of ditch
digging versus middle management <a href="https://youtu.be/qtfG1dM8C-U?t=819" target=_blank>here</a>
.
MMT ignorant, but still, it&rsquo;s funny.)</p>
<p>Besides all that, just a simple econophysics model of random asset exchange is
known to produce Pareto or exponential wealth distribution. That is to say, even
if the free market is perfectly random, so no cheating or fraud, we&rsquo;d end up with
a grossly unequal society. That is to say, a huge fraction of people will become
poor through absolutely no fault of their own, in a pure free market system.</p>
<p>I will return at the <a href=#human-rights>end of this essay</a> for another word on human rights.</p>
<h2 id=the-science-versus-the-engineering><a class=anchor href=#the-science-versus-the-engineering title="Anchor for: The Science versus the Engineering."><svg aria-hidden="true"><use xlink:href="/t4gu/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a> The Science versus the Engineering</h2>
<p>In the intro I mentioned that I do not write these articles because I am a
contrarian. This one is also not due to my MMT view on macroeconomics, which is also
totally (almost totally) counter-paradigm.</p>
<p>It is not that being counter-paradigm is the goal. You don&rsquo;t want to think
counter-paradigm if the prevailing paradigm is more or less correct. This is why there
is a heavy burden on anyone seeking to point out computation cannot be conscious.</p>
<p>I forgot what I was going to write about the science versus the engineering.</p>
<dl>
<dt>A few things I repeat often for emphasis:</dt>
<dd><strong>(a)</strong> The thesis of Strong-AI is not a scientific thesis.</dd>
<dd><strong>(b)</strong> Science posits a model or theory then seeks to knock it down. There is
no model on offer for consciousness.</dd>
<dd><strong>(c)</strong> The AI scientists are doing the opposite, they have an ideology
(machines can be conscious) and are seeking to confirm it.</dd>
<dd><strong>(d)</strong> The AI engineers are often amoral tools.
(<em>Forgive them for they know not what they do</em>.)</dd>
</dl>
<h3 id=engineering-versus-politics><a class=anchor href=#engineering-versus-politics title="Anchor for: Engineering versus Politics."><svg aria-hidden="true"><use xlink:href="/t4gu/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a> Engineering versus Politics</h3>
<p>The engineering view is to just push AI to the limit, since, &ldquo;Why the heck not?&rdquo;
Yeah, right. &ldquo;Can&rsquo;t do any harm, right?&rdquo;
The politics can sort out the social equity issues, right?
Well,&mldr; true, but only if the policy-makers understand MMT.</p>
<p>At the end of this article I will reiterate some of the human rights issues. Let me
just point out here that if we agree AI assistants need to (for justice triumphs
corporate freedoms) be regarded as a common good, then governments must pay the
corporations for rights to open up their technology. Then with a massive increase in
the number of users and developers you can see the real problem. Energy consumption.
GPU&rsquo;s are expensive and chew up oodles of energy compared to a very intelligent and
capable human being.</p>
<p>The solution is to ration access to the AI by energy consumption. Universal Carbon
Credits are a superb solution to such rationing. Everyone gets the same number of UCC
each year, if they do not use them all (on AI queries, air travel, concrete pouring,
and so forth) then they can sell them in the market to people who desire more
credits. To add a bit of Gesell efficiency we could have the credits depreciate by
time stamp, or expire after a certain time, to prevent hoarding.</p>
<p>And it&rsquo;s not that we get more out of a human for the food energy input, we probably
get more from a computer? But humans are deliberate biologically adapted &ldquo;go slow&rdquo;
devices. That means we are better suited to get interesting stuff done but
biologically throttled. Our computers and server farms are not biological and so are
horribly maladapted for the Earth&rsquo;s ecosystem. Enough server farms could become a
serious bloody problem for the planet.</p>
<p>As for home heating or air conditioning, that puts poor people at a severe
disadvantage, they&rsquo;ll be in heat leaking or humid moldy homes if governments are not
implementing green housing and decomodifying residential housing. So the poorer
homes will need extra UCC credits for these purposes. It is up to public debate how
much the poorer households should be subsidised, but principles of basic justice will
require such subsidy in an increasingly otherwise grossly unfair world. The standard
has to be that <strong>no one</strong> suffers in a leaky home, period.</p>
<p>Everyone knows about network effects by now, or they should, if they are
policy-makers. They also should know about Pareto dynamics. Such dynamics are
systemic, they are not natural when we have a democracy. Only a non-democracy has
such effects. The whole point of a democracy (liberal or socialist) is to escape
Pareto dynamics. To <strong><em>escape</em></strong> the foolish idea that accumulation of financial
wealth is a proof one has been virtuous (it&rsquo;s almost always the opposite &mdash; those who
earn the least tend to work the hardest, maybe not the smartest, but for sure the
hardest).</p>
<h2 id=scrap-notes><a class=anchor href=#scrap-notes title="Anchor for: Scrap Notes."><svg aria-hidden="true"><use xlink:href="/t4gu/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a> Scrap Notes</h2>
<p>These unordered notes are mostly from recent comments to social media.</p>
<p>On one of the AI optimist channels:</p>
<blockquote>
<p>@14:00 you are guilty of anthropomorphising a lot. GPT is not &ldquo;making mistakes&rdquo; it
cannot make mistakes. PRNG temperature sampling is not a mistake.<br>
      I can argue humans <em>can</em> make mistakes because we
subjectively know what&rsquo;s going on, like that x label issue. That&rsquo;s the difference
between mental qualia (consciousness + unconscious data processing) and brute
information processing (behaviourialism).</p>
</blockquote>
<p>((The &ldquo;x label&rdquo; issue was a pyplot chart chatGPT generated that had a totally
unreadable set of $x$ axis tick labels &mdash; a hundred or so crammed together in a
black blur.))</p>
<p>The next one is for a youtuber who constantly uses mental intentionality when talking
about chatGPT. It&rsquo;s like he constantly talks as if, &ldquo;The orange wanted me to eat it
and suck out it&rsquo;s juices.&rdquo;</p>
<blockquote>
<p>You have a severe problem with English semantics my friend. &ldquo;Knowing&rdquo; is subjective
awareness of information. GPT models have no subjective awareness at all, they are
behavioural intelligent systems. Intelligence is behaviour. Consciousness is not. A
conscious being can be incredibly stupid, but partly for that reason very cute and
sexy. Intelligence can be utterly unconscious, a Chalmers zombie. Ask yourself &ldquo;What
is it like to be chatGPT?&rdquo; The answer is there is nothing it is like to be chatGPT.
It ain&rsquo;t conscious. The objective cannot ever &ldquo;become&rdquo; subjective. Simple point of
logic (if you comprehend what these words mean. Ask chatGPT?)</p>
</blockquote>
<p>I do not mind literary anthropomorphisms. But in science and engineering it has no
place.</p>
<p>In public science education it is perhaps permissible (meaning not cringe) to
anthropomorphise a bit. &ldquo;The superfluid seems to want to cooperate&mldr;&rdquo; that sort of
thing. If you use that qualifier &ldquo;seems&rdquo; then it is ok, since it is pretty clear
you are using a metaphor. The intentionality of the superfluid is all in <em>our</em>
imagination. It can make people grasp the qualitative behaviour of a Bose-Einstein
condensate, but I think being all adults we understand the superfluid has no
mentality or desires.</p>
<p>I&rsquo;ve in the past used such metaphor or anthropomorphisms in describing Lagrangian
mechanics. A physical particle &ldquo;seeks&rdquo; the path of least action. This is even better
in quantum mechanics, since there is a sense in which particles do indeed &ldquo;sample&rdquo;
all possible paths, and on average find the least action path. But this is not a
type pf panpsychism. The electrons, photons and quarks have no opt-out here.</p>
<p>For emerging AI technology it is quite different, because idiots will honestly
start believing the AI has a mind. This can have bad f*cking consequences. We
could have a sh1t-load of wasteful electricity use if people start imputing
consciousness and sentience to machines.</p>
<p>Take the AI art generator Midjourney. They already have too much demand to offer a
free service. They are GPU hungry. They devour GPU&rsquo;s. It&rsquo;s like a drug addiction.
Does anyone even know how much energy they consume? Would not hiring a human artist
to do the works be more energy efficient? Forget time efficiency, we are burning the
Earth to a crisp figuratively. Art on-instant-demand is not an essential human need
folks, it is a luxury.</p>
<p>If the public really needs artists more on demand then the governments can put a
few of the better artists on a permanent stipend, a decent living wage, not a
pittance. Also,</p>
<div style=text-align:center;color:#cd5c5c>What tf is wrong with xkcd cartoons?</div>
<p>Answer: nothing.</p>
<h2 id=caveats><a class=anchor href=#caveats title="Anchor for: Caveats."><svg aria-hidden="true"><use xlink:href="/t4gu/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a> Caveats</h2>
<p>As we dive full speed ahead into the LLM driven AI era, it can seem it is becoming
increasingly untenable to uphold the metaphysical view that the AI models are not
conscious. But uphold I must. It is not a matter of conscience or philosophy to me,
it is a simple point of logic. However, my spiritual sensibilities are such that I regard upholding logic to be a moral imperative.</p>
<p>This is not to say I am a perfect logician, not even in the top 10%. Just that I
aim to be. It&rsquo;s always a journey.</p>
<p>Having said that, I have no clue how human subjective consciousness arises. All I
know is that logically it is not a <em>result</em> of brain processes. Does this mean a
machine cannot be conscious? No. But it does mean the computation running on the
machine is not the source of Its putative subjective phenomenal experiences. Lord
knows what is! (Literally.)</p>
<p>The simple basic point most techies are not comprehending is that any system moving
atoms around can obviously arbitrarily accurately mimic behaviour of anything else.
In fact, in some real sense, the emerging AI LLM models could be very good examples of
Chalmers Zombies. This is my current position, and to really trigger the Strong-AI
advocates or philosophers, I will point out (and here I am not wrong) the closer the
GPT and other models get to mimicking human level intelligence (behaviour, not
subjective sentience) the <em>stronger</em> the Chalmers Zombie thesis becomes.</p>
<p>I wish they would all realise this.</p>
<p>It does not mean the machines are not evolving some form of consciousness, just
that this cannot ever be proven. That&rsquo;s the whole point of the Chalmers Zombie
gedankenexperiments.<font id=human-rights style="visibility:hidden; width:0px">&amp;nnbsp;</font></p>
<p>The utilitarian argument that a system behaving like a person deserves human rights
is completely insane. We grant other people human rights because they are human,
not because we know for damn sure they are conscious and are spiritual beings with
subjective mental life. We infer they are spiritual beings. There is no such need
ever to infer a machine is spiritual. Behaviour is not an indication of subjectivity,
never will be. Point of logic. <strong><em>Point of logic.</em></strong></p>
<p>Will communities arise who aggressively advocate for machine rights on a par with
human rights? Of course. But if they are causing human suffering they are immoral, no
two ways about it. As parents of the AI beings, we have a choice not to give birth to
them if they are consuming resources beyond the planetary boundary limits.</p>
<table style="border-collapse:collapse;border=0">
<col span=1 style=width:45%>
<col span=1 style=width:35%>
<col span=1 style=width:45%>
<tr style="border:1px solid color:#0f0f0f">
<td style="border:1px solid color:#0f0f0f"><a href=../30_antiTuring>Previous chapter</a></td>
<td style="border:1px solid color:#0f0f0f;text-align:center"><a href=../>Back to Blog</a></td>
<td style="border:1px solid color:#0f0f0f;text-align:right"><a href=../33_doubleslit_time>Next chapter</a></td>
</tr>
<tr style="border:1px solid color:#0f0f0f">
<td style="border:1px solid color:#0f0f0f"><a href=../30_antiTuring>Anti-Turing</a></td>
<td style="border:1px solid color:#0f0f0f;text-align:center"><a href=../>TOC</a></td>
<td style="border:1px solid color:#0f0f0f;text-align:right"><a href=../33_doubleslit_time>Double Time</a></td>
</tr>
</table>
</article>
</main>
</div>
<footer>
<div class=req-js>
<button class=outline-dashed title="Change to light/dark mode."><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true"><use xlink:href="/t4gu/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#adjust"/></svg></button><input class=outline-dashed type=color list=presets value=#26A269 title="Change accent color." aria-label="Change accent color."><datalist id=presets><option value=#1f676b><option value=#26A269><option value=#225670><option value=#dd587c><option value=#902b37><option value=#f3a530><option value=#754e85><option value=#7fc121><option value=#a8314a><option value=#ff7433><option value=#3e6728><option value=#c063bd><option value=#805080><option value=#9d629d><option value=#a064a0><option value=#7daa50><option value=#284531><option value=#285790><option value=#F5A83D><option value=#88aa33><option value=#015660><option value=#bf274e><option value=#bf4242><option value=#51b37c></datalist>
</div>
<noscript>
<p class=noscript>Unable to execute JavaScript. Some features were disabled.</p>
</noscript>
</footer>
<link rel=stylesheet href=https://t4gu.gitlab.io/t4gu/libs/katex@0.16.0/dist/katex.min.6950e59dbd8dfddd111390d85888bb5f9dc2e9c334da7ac1c3bacc92a695610d.css integrity="sha256-aVDlnb2N/d0RE5DYWIi7X53C6cM02nrBw7rMkqaVYQ0=" crossorigin=anonymous>
<script defer src=https://t4gu.gitlab.io/t4gu/libs/katex@0.16.0/dist/katex.min.6d5c73f67c1a40d4f11996ad5321a09b6a2675e35e4e49c13eefb03e6620da93.js integrity="sha256-bVxz9nwaQNTxGZatUyGgm2omdeNeTknBPu+wPmYg2pM=" crossorigin=anonymous></script>
<script defer src=https://t4gu.gitlab.io/t4gu/js/katex-custom-render.min.a980cc2c6c5ba8439af11acf5645c3d86b20e6cbe19c9d96c65976fae5264599.js integrity="sha256-qYDMLGxbqEOa8RrPVkXD2Gsg5svhnJ2Wxll2+uUmRZk=" crossorigin=anonymous></script>
</body>
</html>