<!doctype html><html lang=en data-mode=dark><head prefix="og: http://ogp.me/ns#"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.96.0"><meta name=theme content="Color Your World -- gitlab.com/rmaguiar/hugo-theme-color-your-world"><title>Free Botherations</title><meta name=author content="Bijou M. Smith"><meta name=robots content="index follow"><link rel=canonical href=https://4geons.github.io/blog/24_freebotherations/><meta property="og:site_name" content="Topological 4-Geon Theory Unchained"><meta property="og:title" content="Free Botherations"><meta property="og:url" content="https://4geons.github.io/blog/24_freebotherations/"><meta property="og:type" content="article"><meta property="article:published_time" content="2023-03-15"><meta property="article:modified_time" content="2023-03-15"><meta property="og:updated_time" content="2023-03-15"><meta name=twitter:dnt content="on"><meta name=theme-color content="#222"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="default"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebSite","@id":"https://4geons.github.io/"},"headline":"Free Botherations","description":"","url":"https://4geons.github.io/blog/24_freebotherations/","inLanguage":"en","datePublished":"2023-03-15","dateModified":"2023-03-15","wordCount":"3829","publisher":{"@type":"Person","name":"Bijou M. Smith"},"author":{"@type":"Person","name":"Bijou M. Smith","description":"Random mathematician."}}</script><link rel=stylesheet href=https://4geons.github.io/css/main.min.d33233e3d0eb633ea1fbb9e17553fe7c8ff07875b91d8186e046a48480987c8e.css integrity="sha256-0zIz49DrYz6h+7nhdVP+fI/weHW5HYGG4EakhICYfI4=" crossorigin=anonymous><noscript><meta name=theme-color content="#26A269"><link rel=stylesheet href=https://4geons.github.io/css/noscript.min.503f912ad7e7391597c629c1f7134b77fa61b200f7425671b8fbbe91f62ad657.css integrity="sha256-UD+RKtfnORWXxinB9xNLd/phsgD3QlZxuPu+kfYq1lc=" crossorigin=anonymous></noscript><link rel=preload href=/fonts/OpenSans-Bold.ttf as=font crossorigin=anonymous><link rel=preload href=/fonts/OpenSans-Italic.ttf as=font crossorigin=anonymous><link rel=preload href=/fonts/OpenSans-Regular.ttf as=font crossorigin=anonymous><link rel=preload href=/fonts/Oswald-Bold.ttf as=font crossorigin=anonymous><link rel=preload href=/libs/katex@0.16.0/dist/fonts/KaTeX_Main-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/libs/katex@0.16.0/dist/fonts/KaTeX_Math-Italic.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/libs/katex@0.16.0/dist/fonts/KaTeX_Size2-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/libs/katex@0.16.0/dist/fonts/KaTeX_Size4-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><script src=https://4geons.github.io/js/main.6bc16541f8ff648cb50eea8924e00b94561cf02ec5b5c22ae4b3bce8bab38233.js integrity="sha256-a8FlQfj/ZIy1DuqJJOALlFYc8C7FtcIq5LO86LqzgjM=" crossorigin=anonymous></script></head><body><header><a href=/><img src=https://4geons.github.io/images/t4gu_logo.svg alt="T4GU logo" style=display:flex;width:40px;height:34px;float:left;margin-bottom:-2.5px;margin-right:10px></a>
<a href=/>Topological 4-Geon Theory Unchained</a><nav aria-label="Main menu."><ul><li><a class=btn href=/>Home</a></li><li><a class=btn href=/philosophy/>Philosophy</a></li><li><a class=btn href=/theory/>Theory</a></li><li><a class=btn href=/blog/>Posts</a></li><li><a class=btn href=/contact/>Contact</a></li><li><a class=btn href=/donations/>Donate</a></li></ul></nav></header><div class=filler><main><article><header><h1>Free Botherations</h1><p>Published on <time datetime=2023-03-15>2023-03-15</time></p></header><details class=toc open><summary class=outline-dashed>Contents</summary><nav id=TableOfContents><ul><li><a href=#free-bananas---tldr>Free Bananas - TL;DR</a></li><li><a href=#a-deeper-dive-into-the-banana-pool>A Deeper Dive into the Banana Pool</a><ul><li><a href=#on-those-who-think-the-c-compiler-understands-c-language>On those who think the C Compiler understands C Language</a></li></ul></li><li><a href=#i-am-therefore-i-think-----and-also-youre-insane>&ldquo;I Am Therefore I Think&rdquo; &mdash; and also you&rsquo;re insane</a><ul><li><a href=#what-might-friston-mean>What Might Friston Mean?</a></li></ul></li><li><a href=#is-the-free-energy-principle-school-any-great-use>Is the Free-Energy Principle school any great use?</a></li></ul></nav></details><p>All this distraction writing about AI and platonism is sucking my time away from
macroeconomics and T4G, but I hope for posterity all these musing are useful to some
kids who might get some inspiration. Today <em>The Algorithm</em> took me to
<a href=https://www.youtube.com/@MachineLearningStreetTalk target=_blank>Machine Learning Street Talk</a>
and an interesting
<a href="https://www.youtube.com/watch?v=V_VXOdf1NMw" target=_blank>interview with Karl Friston</a>
, an eminent
neuroscientist who has some wacky ideas about cognition, relevant to AI and to the
anti-platonistic schools of thought.</p><p>I hate to be combative, so I&rsquo;ll try to review Friston and the so-called
<em>free-energy principle</em> fairly, but I&rsquo;m an apologetic platonist (see
<a href=../19_plates_and_socks>previous posts, 18</a>
and <a href=../20_platonics>19</a>
)
and so will have to call out idiocy as regards blind materialist dogma when I see it.
That&rsquo;s a trigger warning for materialists, so you&rsquo;ve been fairly warned. If you want
to debate me then please <a href=https://ko-fi.com/achrononmaster/ target=_blank>donate</a>
first,
since I cannot live on github/substack views and dislikes alone. This way you are
free to call me an idiot too, but not free to get my response. I may end up agreeing
with you, but you&rsquo;ll have to pay to read that &mdash; at least until such time as my
government employs me to do something more fun filled.</p><h2 id=free-bananas---tldr><a class=anchor href=#free-bananas---tldr title="Anchor for: Free Bananas - TL;DR."><svg aria-hidden="true"><use xlink:href="/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a>Free Bananas - TL;DR</h2><p>The great thing about the internet and the various arxivs, is that a boat load of
cool thinking is no longer locked behind journal pay-walls, and we get to see
interviews with bright thinkers on youtube for free entry (for Zoomers who weren&rsquo;t around in the 80&rsquo;s you need not bother your brains with that comment). There is a
real cost though, opportunity to do better things goes begging. With that in mind, I
am a little torn about how much effort to spend writing about Friston&rsquo;s school of
thought in cognitive science.</p><p>I will thus try to do a quick overview, before diving into specifics, and that way
the tldr crowd can be on their way shortly.
This is my best current synopsis:</p><ol><li>The free-energy principle is a mathematical identity obtained from physical
assumptions about dynamical systems subject to entropy increase (so admitting
statistical descriptions, or equivalently, any high level description ignoring a lot
of molecular level and atomic degrees of freedom).</li><li>As a mathematical identity, the FEP says nothing useful about anything unless there
is a system satisfying the prerequisites of the theorem.</li><li>The use of this principle in cognitive science is a simple tautology, that observes
the outcome of any adaptive evolution (assuming some are energy through-put
organisms) will be organisms which are in a rough sense optimized to minimise a
quantity called &ldquo;surprise&rdquo; (although this does not mean phenomenal conscious
surprise, it is a dopey use of a <em>thick concept</em> in what is really a very narrow
range, and it can be computed from basic information theory estimations.)</li><li>It is possible to form normative models (so no black swans, like extreme altruism
or insanity) of cognitive behaviour by supposing organisms &ldquo;cognate&rdquo; based on
using sensory input to determine actions the organism can take in order to keep the
&ldquo;surprise&rdquo; of their environment low.<br>       <strong>(a)</strong> The terms &ldquo;cognate&rdquo; and &ldquo;surprise&rdquo; are
loaded terms, the latter having been already loosely defined using information
theory, the former entirely undefined, and considered for our purposes to be some
undefined generic sort of computation, although the nature of which is unclear, in
animals it takes place mostly in the brain rather than individual cells.<br>       <strong>(b)</strong> There is no theory in FEP related
literature covering anything like subjective mental qualia. Qualia are not in the
realm of FEP applications in cognitive science, so FEP stuff is all purely
behavioural. No semantics.</li><li>FEP applies to single-celled organisms and plants, and things without brains.
Which tells you the &ldquo;cognition&rdquo; we are talking about is probably not consciousness,
not by a long stretch (unless you believe in panpsychism). So there is no explanation
for subjective consciousness in any of this program, so it has nothing to do with
true genuine &ldquo;AI&rdquo; (artificial consciousness, or sentient programs or sentient robots).</li><li>While FEP is a theorem, the application in any given model is contingent.
So the FEP models can be falsified, simply by finding organisms that display your
<em>generalized</em> cognitive capacity but which do not satisfy the FEP assumptions; or by
finding predictions of the model that are not born out by facts.</li></ol><h2 id=a-deeper-dive-into-the-banana-pool><a class=anchor href=#a-deeper-dive-into-the-banana-pool title="Anchor for: A Deeper Dive into the Banana Pool."><svg aria-hidden="true"><use xlink:href="/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a>A Deeper Dive into the Banana Pool</h2><p>First, if you want a view on AI quite similar to mine, listen to
<a href="https://www.youtube.com/watch?v=e1M41otUtNg" target=_blank>Mark Bishop</a>
.
FWIW I do not think much of the argument derived from Putnam, since a hard-nosed
materialist can always adopt mysticism and claim some sort of panpsychism generates
conscious qualia in <em>any and all</em> physical computations. This is similar to John
Searle&rsquo;s ideas, except Searle mysterianism restricts qualia generation to
hypothetically only certain special biological processes (for lord knows what reason,
he gives no convincing reason other than we know humans are biological organisms).</p><p>The counter-Putnam-Bishop argument is that all computations with the same states are
not equal. It matters how a process goes through the physical states. No one claims
to know what the special types of process are that purportedly generate conscious
qualia, it is simply taken on faith, by materialists. They have to take it on faith,
because there is no other option for them, except to accept Putnam&rsquo;s <em>reductio ad
absurdem</em> as valid which thus ridicules the whole idea of a computational basis for
consciousness.</p><p>The more extended Church-Turing thesis is thus that not all computations generate
qualia, only a special type, and the comptutional sequence of states is not the
generator, the generator of qualia is something else, &ldquo;yet to be determined.&rdquo;
Presumably this something else involves at a minimum the time between states in the
computer registry, and for the ‘quantum consciousness’ quacks${}^\dagger$, presumably
also a certain amount of entanglement.</p><p>${}^\dagger$I do not mean to belittle crazy ideas, and it is not that I think
consciousness is unrelated to a physics which is quantum mechanical, I think
consciousness definitely only manifests in universes with something <em>like</em> quantum
mechanics. What I ridicule are people who think they know how quantum mechanics
accounts for consciousness. Those people are completely deluded. The correct way (I
think) to think about the relationship is that consciousness cannot get manifested in
a universe which lacks something akin to quantum dynamics, but the quantum mechanics
is not the generator of the qualia, no more than classical mechanics can be the
generator.</p><p>Supposing any and all computations generate qualia is not the claim here, the claim
is only that <em>physical</em> computations (any and all of them) generate qualia. No one
ever says how though, so it is total bullsh*t (until proven otherwise).</p><blockquote><p>Good science is the opposite of the law, you are guilty until
proven innocent, and no science is ever proven innocent.</p></blockquote><h3 id=on-those-who-think-the-c-compiler-understands-c-language><a class=anchor href=#on-those-who-think-the-c-compiler-understands-c-language title="Anchor for: On those who think the C Compiler understands C Language."><svg aria-hidden="true"><use xlink:href="/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a>On those who think the C Compiler understands C Language</h3><p>Walid Saba, normally a reasonable guy, made an absurd claim in one of the MLST
<a href="https://www.youtube.com/watch?v=e1M41otUtNg" target=_blank>comments sections</a>
,
he claimed machine &ldquo;understanding&rdquo; is possible, he cited the Python language
compiler as an example: it must understand the Python language, he
suggested. Here was my reply:</p><blockquote><p>Bollocks mate. The python compiler does what van Rossum (et al) told it to do, and
what subsequent users command. The understanding is all derivative from the coders.
You cannot mathematicize mental qualia because they&rsquo;re not mathematical things. But
if you choose to define &ldquo;understanding&rdquo; in black-box operation terms, then of course
you can program a machine to &ldquo;understand.&rdquo; But it&rsquo;ll never be generating subjective
mental qualia, so cannot understand in the sense I would define it.<br>      There is no test for such subjective inner
sentience either, that&rsquo;s Turing&rsquo;s point. And Nagel&rsquo;s. It is an imitation game, not a
mental qualia generation game. So if perchance someone grows a computer that gains
subjective mental qualia generative capacity, no one will ever know. It&rsquo;s not a
falsifiable hypothesis.</p></blockquote><p>Also, there is no &ldquo;It&rdquo; that is &ldquo;the python compiler.&rdquo; So there&rsquo;s no conscious
subject to speak of. In black-box input-output terms, you could identify an
operational capacity of &ldquo;understanding&rdquo; in almost anything. Which makes it almost
meaningless. Better to stick to what most normal people think of when they say,
&ldquo;I understand.&rdquo; It is not a mathematically definable attribute.</p><p>My colleague, Douglas the MMT Macro Trader, would here object (I know, because he
has) that all humans are doing is derivative from past human activity too, so doesn&rsquo;t
my argument apply to us as well?</p><p>My answer is, well maybe for <em>you</em> yes. But not for me.</p><p>I know I experience mental qualae. I do not know for sure you all do. But I can
legitimately infer you also experience qualia, as a gesture of humanity, the
Silver Rule (I would not wish you to assume I am not conscious either).</p><p>Why do I not extend the same gesture to a machine that passes all imitation games?</p><p>Well, you see, I might. But I cannot extend the gesture to a piece of software, nor
the machine it is running on, I can only extend the gesture of inferring the thing is
conscious to a system as a whole. But then, I have to be highly sceptical, because of
the Nagel problem: <em>what is it like to be a bat?</em>
I have no frickin&rsquo; idea, and so no clue about whether bats have minds or are not just
zombies with sophisticated behaviours.</p><p>When I say &ldquo;I don&rsquo;t have a clue&rdquo; I also mean the entire body of the science
community has no clue, I&rsquo;m not making a provincial argument here.</p><p>At the very least, I want an entity to be able to do a bit of symbolic algebra,
and not have been programmed to do so, but learned through social interactions. I also
rather fancy I&rsquo;d like to see the entity spontaneously freak out like the blue blazes
if I go anywhere near it&rsquo;s ‘off’ switch. Or whatever the equivalent for a machine is
of moving a hot poker near a monkey&rsquo;s private parts.</p><p>If a Bat or a Monkey can do all this, I will morally be obliged to treat it as
conscious, a non-zombie. Holding out the possibility other animals might have such
hidden capacities, I will treat them with kindness anyway. But I have no care about
the consciousness of a lump of clay, I will tread on that stuff all day long without
any moral qualms. I realize this may seem all gross, selfish, and disgusting for
people who think molecules have feelings, so, ok, I am sorry.</p><p>I do know one human being experiences mental qualia, and so can infer others do too,
but there is no evidence subjective mental qualia arise from brains, so the inference
to machines and other animals cannot be made. It would be a complete leap of faith,
so unscientific. Perhaps morally justifiable, but not scientifically.</p><p>What we do know is that our conscious faculty needs a brain in order to exert
physical causal efficacy. No one has any idea what this causal power is, where it
comes from, or anything of that nature. Once you try to figure it out all that
happens is you go down a reductionist tunnel to the elementary particle gauge forces,
and so remove all notions of the subjective qualia you were trying to account for &mdash;
it&rsquo;s the grandest &ldquo;hand-in-the-cookie-jar problem&rdquo; of all time. The only way to get
the cookie out is either by magic (illusion) or to crumble it, destroying the
cookieness (except for purposes of the Ben & Jerry flavour)</p><p>I think Mark Bishop needs some nuance though. The reason we cannot be living in a
computer simulation is not because, &ldquo;I can feel the sensation of cool water on my
face in a rain shower.&rdquo; That sensational qualia is the reason we cannot be living in a
<em>physical</em> computation. But if you extend the entire meaning of &ldquo;computation&rdquo; to
something very metaphysical, like, &ldquo;thought processes in the Mind of God&rdquo; then
anything is possible, up to logic. No one is going to do this in the AI geek
community though, let&rsquo;s be honest.</p><p>Instead we define a &ldquo;computation&rdquo; as that which can be simulated on an abstract
Turing machine (so we need unphysical infinite tape for starters, but most
philosophers are prepared to grant materialists this loophole. I am.) I doubt having
an infinite tape is going to endow a system with subjective conscious qualae.</p><p>This is where it gets philosophically interesting. If physical computations cannot
generate subjective mental qualia, then what can?</p><p>I appreciate all materialists clearly think either mental qualia are illusions
(illusions to <em>what</em> or <em>whom</em> exactly, if not a mentally aware entity?) or that
physical computations (generalized physical processes) <em>can</em> generate mental qualia.
So they are not going to accept the definition of mental qualia being subjective,
they are committed to objectification. That&rsquo;s completely banana philosophy, but I&rsquo;m
unable to shift their views, except with ridicule, which is ineffective, so will not
waste further effort trying.</p><pre aria-label="Box containing code sample." tabindex=0><code>TODO: this is an article stub.
More to come later.
</code></pre><h2 id=i-am-therefore-i-think-----and-also-youre-insane><a class=anchor href=#i-am-therefore-i-think-----and-also-youre-insane title="Anchor for: &ldquo;I Am Therefore I Think&rdquo; &mdash; and also you&rsquo;re insane."><svg aria-hidden="true"><use xlink:href="/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a>&ldquo;I Am Therefore I Think&rdquo; &mdash; and also you&rsquo;re insane</h2><p>Later I should watch the talk, but Friston has this lecture with that title, minus
the insanity clause. I&rsquo;ll swallow the clickbait and do the idiot thing in only
commenting on the title! It&rsquo;s ok to use a clickbait title to rail against insanity
even if the talk beneath the title is sound and moderate, provided that&rsquo;s what you
declare to be doing, constructing a strawman. That&rsquo;s what I am doing.</p><p>OK, so to be brief, &ldquo;I Am therefore I Think&rdquo; is a massive case of warped logic.
Sounds like panpsychism, poorly motivated. However, there is an easy way to
reconcile it with decency.</p><p>Any entity that knows it exists, and can contemplate &ldquo;I Am&rdquo; will <em>ipso facto</em>
know that it thinks. Before it even gains a social construction of the verb &ldquo;to think.&rdquo;</p><p>There are plenty of things I have no language for, but which exist. People will say
that I then have a mental language, but that&rsquo;s a lot of bullsh$\ast$t. Our mental
qualia are not a language. However, if you are Jerry Fodor or someone with a galaxy
brain, for sure you can redefine the meaning of &ldquo;language&rdquo; and claim mental paint is
a form of inner &ldquo;language of thought.&rdquo; To my mind this gets us nowhere, because
without grist backing your definition (what is <em>the mental</em>) your definition has no
practical use. It becomes just academic philosophy word gaming.</p><p>So to rescue Friston&rsquo;s insanity we change the statement to a true one:</p><blockquote><p>I have the knowledge &ldquo;I Am,&rdquo; therefore I think.</p></blockquote><p>Which is sensible, and is just restating Descartes in a subtler way. It is a partial
definition of what subjective knowledge connotes. It connotes subjective awareness,
so there is a conscious entity, an &ldquo;I&rdquo;. If a thing merely exists, it does not
necessarily have any &ldquo;Am-ness&rdquo; about it, so cannot even think to think it is
thinking.</p><p>But surely Friston cannot be so lame? There must, methinks, be something else he is
getting at by inverting Descartes. What is it?</p><p>After all, the inference,
$$
(\text{I Think}) \stackrel{?}{\Rightarrow} (\text{I Know I exist})
$$
is unidirectional. If there is no conscious &ldquo;I&rdquo; then we cannot go in the reverse
direction. However, the above implication is incomplete, for the above reason. One
must not only be thinking, one must have the thought of oneself as a being. Then the
implication becomes a tautology.</p><p>I am going to play my guessing game to motivate reading or listening more to Friston.
Without the game I could not tolerate the tedium. For the set-up I am going to
conjecture what Friston might be talking about.</p><h3 id=what-might-friston-mean><a class=anchor href=#what-might-friston-mean title="Anchor for: What Might Friston Mean?."><svg aria-hidden="true"><use xlink:href="/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a>What Might Friston Mean?</h3><p>Could it be that Friston means nothing more than the banality that any system which
is self-aware must also be thinking? I think that is what he&rsquo;ll be saying, using a
few thousand superfluous words.</p><p>However, from what I can tell after studying the ideas a bit there is really nothing
in the FEP/Active-Inference paradigm that relates to subjective consciousness, so I
rather quickly tired of the work, because it ends up just being another useful tool
for studying and modelling complex behaviour. Like neural networks.</p><p>The distinguishing feature f all such tools is that they escape the need to write
down physics governing equations. I you need to discover a set of PDE&rsquo;s for every damn
complex system you are going to be intellectually paralysed. Instead applied complex
system scientists have invented all sorts of models for avoiding the need to write
down governing PDE or ODE equations.</p><p>These range from cellular automata, agent-based systems, neural nets,
Bayesian nets, expert-systems, GOFAI symbolics, and many others I&rsquo;ve long since
forgotten.</p><p>The trick is, you want to use a few hundred thousand words to confuse your audience,
to hide the banality. The banality being that he will be using the concept of
&ldquo;self-awareness&rdquo; as a proxy for thinking, without defining precisely what
&ldquo;self-awareness&rdquo; connotes because no one knows what it connotes, since no one knows
what the hell consciousness is in essence.</p><p>Thus, I conjecture, Friston is saying nothing much more than:</p><div style=text-align:center;font-style:italic>A self-aware system is self-ware.</div><p>But he will do so in so many more words such that everyone will think he is saying
something profound. This is why academics get paid the big bucks.</p><p>When we professionalize thinking we degrade our thought. (Not always ok, there are
some good folks. Also, just because I am not paid to think does not make my writing
more profound. I shouldn&rsquo;t have to point this out, but you are never free of the
pedants, so a little effort to calm them down
[or do I mean clam them down?] might not go astray.)</p><p>I am also going to hedge a bit though.</p><p>I am pretty sure the FEP/AcIn ideas will be usefully pplied to what they call &ldquo;machine learning&rdquo; but which I call <em>behavioural modelling</em>. I think the FEP/AcIn stuff will have useful insights for behavioural modelling.</p><p>It should also have useful insights for cognitive science, because the input&ndash;output aspects of cognition are a special type of behaviour.But I suspect that&rsquo;s about the end of it. A useful modelling paradigm. Like the Euler equations are a useful model for some fluid lows.</p><p>To write further I guess I&rsquo;ll have to listen Friston&rsquo;s tedious lecturing. Maybe
tomorrow I&rsquo;ll write an update.</p><pre aria-label="Box containing code sample." tabindex=0><code>TODO: what was Friston thinking?
</code></pre><pre aria-label="Box containing code sample." tabindex=0><code>TODO: had some other things to include...
</code></pre><h2 id=is-the-free-energy-principle-school-any-great-use><a class=anchor href=#is-the-free-energy-principle-school-any-great-use title="Anchor for: Is the Free-Energy Principle school any great use?."><svg aria-hidden="true"><use xlink:href="/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a>Is the Free-Energy Principle school any great use?</h2><p>Yes and no.</p><p>It&rsquo;s of no use for gaining insights into human subjective consciousness, because the
FEP/AcIn school is descriptive, and purely mathematical. If conscious deliberation
conforms to FEP constraints that is not because of the FEP dictating anything, it is
only because whatever a conscious being happens to be, their body + brain dynamics is
temporarily satisfying the presumptions of the FEP theorem.</p><p>I can use a quantum physics analogy or metaphor. Suppose Bohm Pilot waves are the
reality. Does this mean Many worlds is useless? No. I can still use Many Worlds
Theory to make predictions, perfectly in accord with reality.</p><p>Whatever a conscious organism is doing when &ldquo;thinking&rdquo; it is not implementing a
free-energy minimisation procedure, not at all. It&rsquo;s dynamics are historically
dependent, and black swans can occur all over the show that grossly violate the FEP
demands. We operate under such non-FEP all the time. But on average we probably
satisfy the FEP constraints. So it is not the FEP that is driving conscious beings.
But the FEP/AcIn does a good job nonetheless in describing certain normative aspects
of conscious deliberation.</p><p>So like a Many Worlds QM is <em>useless for metaphysics</em> if in fact reality is Bohmian
(or think the converse if you&rsquo;re a Many Worlder) the FEP/AcIn paradigm is useless for
understanding consciousness. However, FEP/AcIn could be terrific for designing
automated systems for specialist tasks. Just as Many Worlds might be very useful for
designing quantum circuits (I actually doubt that is true, but more than few quantum
computer engineers are Many Worlders).</p><p>((I might be being unfair to Friston&rsquo;s school here, maybe they never claimed
FEP/AcIn is research aimed at understanding consciousness?))</p><p>Ultimately, what I think is going on under the FEP &ldquo;Active Inference&rdquo; banner of
thought is something descriptive. This turns out to be useful in designing
&ldquo;intelligent&rdquo; systems (automated intelligence, not genuine intelligence).</p><p>The way I think things work in the real world is that consciousness is pretty darn
unique, and can be goal-directed, or teleological, but that implies some
as-yet-unknown top-down causation. The FEP and Active Inference do not show us how
top-down causation can occur. This means FEP/AcIn is a research paradigm for getting
better automation. It is not a possible research program for understanding human
types of sentience (subjective consciousness).</p><p>A conscious being can thus work outside the parameters of FEP/AcIn, and we see this
all the time in what I&rsquo;d call &ldquo;black swans&rdquo; in real world societies, altruism and
cooperation extending beyond minimising free-energy, or for that matter insanity, war
and violence going beyond the FEP in the other direction.</p><p>Thus, if you wish to design an automated system with a mimicry for &ldquo;intelligence&rdquo;
(which is nothing but a synonym here for sophisticated behaviour) then the FEP/AcIn
paradigm is a good way to go about designing such systems.</p><p>Why does it work?</p><p>It works because most systems we would employ FEP/AcIn for use at particular tasks
are going to be working in controlled environments. They are going to be operating
under Gaussian probability distribution assumptions, unless explicitly programmed not
to, which might be considered how you specialize. A machine system would specialize
in the broadest sense by having non-Gaussian models for particular narrow tasks.</p><p>But put them in front of a luddite with some C4 (for example, or anything you did not
train your automated system to encounter) and I think your FEP/AcIn robot is going to
experience a sudden black swan where it&rsquo;s FEP optimization little engine gets
catastrophically rendered completely useless.</p><p>Conscious beings can suffer from similar catastrophe of course, but we are far more
robust against such black swans, because we&rsquo;re conscious. This has nothing to do with
FEP. The black swan is beyond any FEP/AcIn rescuing.</p><p>It is a feature of complex non-linear dynamical systems that specialization comes at
a cost: one cannot be a generalist. The entire history of human civilization is, in
part, a story of our ability to use technology and science to get specialist systems
to do what no human can ever do, even right down to mass manufacturing paper clips.
This has prolonged human civilization, it has allowed us to all remain, for the most
part, generalists. Thus without any further speciation.</p><p>The highly specialized human is a basket-case of ineptitude. Highly unfit for
survival, unless protected by a caring society.</p><table style="border-collapse:collapse;border=0"><col span=1 style=width:35%><col span=1 style=width:25%><col span=1 style=width:35%><tr style="border:1px solid color:#0f0f0f"><td style="border:1px solid color:#0f0f0f"><a href=../23_pygeons>Previous chapter</a></td><td style="border:1px solid color:#0f0f0f;text-align:center"><a href=../>Back to Philosophy</a></td><td style="border:1px solid color:#0f0f0f;text-align:right"><a href=../25_formal_models>Next chapter</a></td></tr><tr style="border:1px solid color:#0f0f0f"><td style="border:1px solid color:#0f0f0f"><a href=../23_pygeons>Computational Geons</a></td><td style="border:1px solid color:#0f0f0f;text-align:center"><a href=../>TOC</a></td><td style="border:1px solid color:#0f0f0f;text-align:right"><a href=../25_formal_models>Formal Models</a></td></tr></table></article></main></div><footer><div class=req-js><button class=outline-dashed title="Change to light/dark mode."><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true"><use xlink:href="/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#adjust"/></svg></button><input class=outline-dashed type=color list=presets value=#26A269 title="Change accent color." aria-label="Change accent color."><datalist id=presets><option value=#1f676b><option value=#26A269><option value=#225670><option value=#dd587c><option value=#902b37><option value=#f3a530><option value=#754e85><option value=#7fc121><option value=#a8314a><option value=#ff7433><option value=#3e6728><option value=#c063bd><option value=#805080><option value=#9d629d><option value=#a064a0><option value=#7daa50><option value=#284531><option value=#285790><option value=#F5A83D><option value=#88aa33><option value=#015660><option value=#bf274e><option value=#bf4242><option value=#51b37c></datalist></div><noscript><p class=noscript>Unable to execute JavaScript. Some features were disabled.</p></noscript></footer><link rel=stylesheet href=https://4geons.github.io/libs/katex@0.16.0/dist/katex.min.6950e59dbd8dfddd111390d85888bb5f9dc2e9c334da7ac1c3bacc92a695610d.css integrity="sha256-aVDlnb2N/d0RE5DYWIi7X53C6cM02nrBw7rMkqaVYQ0=" crossorigin=anonymous><script defer src=https://4geons.github.io/libs/katex@0.16.0/dist/katex.min.be85dd55a5a5cdd485ed96e6c7d6ac9a8ebd36e13cfa5e8193b2be803d528cb8.js integrity="sha256-voXdVaWlzdSF7Zbmx9asmo69NuE8+l6Bk7K+gD1SjLg=" crossorigin=anonymous></script>
<script defer src=https://4geons.github.io/js/katex-custom-render.min.69ee75fc26740b7c2309940e37a9ef7efe30719f39fe271514b94dba111ef812.js integrity="sha256-ae51/CZ0C3wjCZQON6nvfv4wcZ85/icVFLlNuhEe+BI=" crossorigin=anonymous></script></body></html>