<!doctype html><html lang=en data-mode=dark>
<head prefix="og: http://ogp.me/ns#">
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta name=generator content="Hugo 0.92.2">
<meta name=theme content="Color Your World -- gitlab.com/rmaguiar/hugo-theme-color-your-world">
<title>Anti-Turing tests</title>
<meta name=author content="Bijou M. Smith">
<meta name=robots content="index follow">
<link rel=canonical href=https://t4gu.gitlab.io/t4gu/blog/31_antituring/>
<meta property="og:site_name" content="Topological 4-Geon Theory Unchained">
<meta property="og:title" content="Anti-Turing tests">
<meta property="og:url" content="https://t4gu.gitlab.io/t4gu/blog/31_antituring/">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2023-05-17">
<meta property="article:modified_time" content="2023-05-17">
<meta property="og:updated_time" content="2023-05-17">
<meta name=twitter:dnt content="on">
<meta name=theme-color content="#222">
<meta name=apple-mobile-web-app-capable content="yes">
<meta name=apple-mobile-web-app-status-bar-style content="default">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebSite","@id":"https://t4gu.gitlab.io/t4gu"},"headline":"Anti-Turing tests","description":"","url":"https://t4gu.gitlab.io/t4gu/blog/31_antituring/","inLanguage":"en","datePublished":"2023-05-17","dateModified":"2023-05-17","wordCount":"7179","publisher":{"@type":"Person","name":"Bijou M. Smith"},"author":{"@type":"Person","name":"Bijou M. Smith","description":"Random mathematician."}}</script>
<link rel=stylesheet href=https://t4gu.gitlab.io/t4gu/css/main.min.d33233e3d0eb633ea1fbb9e17553fe7c8ff07875b91d8186e046a48480987c8e.css integrity="sha256-0zIz49DrYz6h+7nhdVP+fI/weHW5HYGG4EakhICYfI4=" crossorigin=anonymous>
<noscript>
<meta name=theme-color content="#26A269">
<link rel=stylesheet href=https://t4gu.gitlab.io/t4gu/css/noscript.min.503f912ad7e7391597c629c1f7134b77fa61b200f7425671b8fbbe91f62ad657.css integrity="sha256-UD+RKtfnORWXxinB9xNLd/phsgD3QlZxuPu+kfYq1lc=" crossorigin=anonymous>
</noscript>
<link rel=preload href=/t4gu/fonts/OpenSans-Bold.ttf as=font crossorigin=anonymous>
<link rel=preload href=/t4gu/fonts/OpenSans-Italic.ttf as=font crossorigin=anonymous>
<link rel=preload href=/t4gu/fonts/OpenSans-Regular.ttf as=font crossorigin=anonymous>
<link rel=preload href=/t4gu/fonts/Oswald-Bold.ttf as=font crossorigin=anonymous>
<link rel=preload href=/libs/katex@0.16.0/dist/fonts/KaTeX_Main-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous>
<link rel=preload href=/libs/katex@0.16.0/dist/fonts/KaTeX_Math-Italic.woff2 as=font type=font/woff2 crossorigin=anonymous>
<link rel=preload href=/libs/katex@0.16.0/dist/fonts/KaTeX_Size2-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous>
<link rel=preload href=/libs/katex@0.16.0/dist/fonts/KaTeX_Size4-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous>
<script src=https://t4gu.gitlab.io/t4gu/js/main.42b683201e75d61e0c2793a3814a2306fd1f036cf6dd7f9ea3b61cd13f2d752e.js integrity="sha256-QraDIB511h4MJ5OjgUojBv0fA2z23X+eo7Yc0T8tdS4=" crossorigin=anonymous></script>
</head>
<body>
<header>
<a href=/t4gu> <img src=https://t4gu.gitlab.io/t4gu/images/t4gu_logo.svg alt="T4GU logo" style=display:flex;width:40px;height:34px;float:left;margin-bottom:-2.5px;margin-right:10px> </a>
<a href=/t4gu> Topological 4-Geon Theory Unchained </a>
<nav aria-label="Main menu.">
<ul>
<li>
<a class=btn href=/t4gu/t4gu/>Home</a>
</li>
<li>
<a class=btn href=/t4gu/t4gu/philosophy/>Philosophy</a>
</li>
<li>
<a class=btn href=/t4gu/t4gu/theory/>Theory</a>
</li>
<li>
<a class=btn href=/t4gu/t4gu/blog/>Posts</a>
</li>
<li>
<a class=btn href=/t4gu/t4gu/contact/>Contact</a>
</li>
<li>
<a class=btn href=/t4gu/t4gu/donations/>Donate</a>
</li>
</ul>
</nav>
</header>
<div class=filler>
<main>
<article>
<header>
<h1>Anti-Turing tests</h1>
<p>
Published on <time datetime=2023-05-17>2023-05-17</time>
</p>
</header>
<details class=toc open>
<summary class=outline-dashed>
Contents
</summary>
<nav id=TableOfContents>
<ul>
<li><a href=#congressional-regulations-on-ai>Congressional Regulations on AI</a>
<ul>
<li><a href=#the-more-real-threats>The (more) Real Threats</a></li>
<li><a href=#sensible-regulations>Sensible Regulations</a></li>
</ul>
</li>
<li><a href=#the-turing-test>The Turing Test</a></li>
<li><a href=#what-is-consciousness>What is consciousness?</a>
<ul>
<li><a href=#what-consciousness-is-not>What Consciousness is Not</a></li>
<li><a href=#the-mental-stress-tests>The Mental Stress Tests</a></li>
</ul>
</li>
<li><a href=#the-searle-emergences>The Searle Emergences</a>
<ul>
<li><a href=#the-jrs-view>The JRS View</a></li>
<li><a href=#the-drh-view>The DRH View</a></li>
<li><a href=#varieties-of-level-emergentism>Varieties of Level Emergentism</a></li>
</ul>
</li>
<li><a href=#supporting-strong-ai-research>Supporting Strong-AI Research</a>
<ul>
<li><a href=#notes>Notes</a></li>
<li><a href=#more-scrap-notes-unordered>More scrap notes (unordered)</a></li>
</ul>
</li>
<li><a href=#weird-non-dualism-dualism>Weird Non-dualism dualism</a>
<ul>
<li><a href=#the-how-of-dualism-or-polyontology>The &ldquo;How?&rdquo; of Dualism or Polyontology</a></li>
</ul>
</li>
</ul>
</nav>
</details>
<p>Following on the series of AI topics, over at
<a href=https://smithwillsuffice.github.io/ohanga-pai/blog/26_statsknowing/ target=_blank>Ōhanga Pai</a>
I had promised a mini-series on what we can expect advanced AI to accomplish.
Today I want to take a step back from the macroeconomics and do another philosophy
post, but related. I want to lay out my positions on whether it is even sensible to
try to define &ldquo;consciousness&rdquo; and if so, even if only partially, how you might &ldquo;test&rdquo;
for consciousness. (Knowing this is a fraught and unscientific question, I will
nevertheless wade into it! Because&mldr; why not?)</p>
<p>To blend with Ōhanga Pai I will start with a brief mention of some political economy
before diving in to the philosophy of mind.</p>
<h2 id=congressional-regulations-on-ai><a class=anchor href=#congressional-regulations-on-ai title="Anchor for: Congressional Regulations on AI."><svg aria-hidden="true"><use xlink:href="/t4gu/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a> Congressional Regulations on AI</h2>
<p>A recent hearing at the US Congress got a number of things right, but a lot wrong.
The overarching fear was &ldquo;job losses&rdquo;. Complete fail! But a fail from <em>both</em> the
AI tech leaders and the Congress representatives.</p>
<p>Let&rsquo;s give them a correct account of things:</p>
<ul>
<li>Automation is a productivity gain story, not an unemployment story.</li>
<li>Unemployment is an unspent income story, and with existing MMT systems governments
can always spend more than their &ldquo;income&rdquo; (tax return, fees, fine, levies) to hire
anyone who is not employed in the private sector.</li>
<li>When governments hire the unemployed there is no wage&ndash;profit spiral inflation
pressure because by definition the private sector bid for those unemployed workers is
zero.</li>
<li>It is a moral duty that government hire all the unemployed, because government
creates all unemployment (in a monetary system).</li>
<li>Imposed legal liabilities create demand for the otherwise worthless fiat currency,
hence unemployment (people needing to earn or borrow the currency to pay the tax
liability).</li>
<li>Tax payments are redemptions, they are not funding the governmetns. The government
has to issue currency first, usually by spending and hiring, before anyone can pay<br>
dime of tax without having to take out bank credit.</li>
</ul>
<p><strong>Comment on 3rd:</strong> A wage&ndash;profit spiral can occur in a type of predator&ndash;prey
dynamical system model (Goodwin models in macroeconomics). The real world in a
monopoly currency issuer monetary economy has no such dynamics by necessity, unless
by policy choice. Unfortunately in most countries today there are many fiscal
policies that are pro-cyclical and so we can see these Goodwin cycles, but they are
constrained, so the price level doesn&rsquo;t continually rise, and wages and profits tend
to cycle in orbits.</p>
<h3 id=the-more-real-threats><a class=anchor href=#the-more-real-threats title="Anchor for: The (more) Real Threats."><svg aria-hidden="true"><use xlink:href="/t4gu/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a> The (more) Real Threats</h3>
<p>When you understand all this, the issue of AI automating away work is a benefit to
humankind. It is not a threat.</p>
<p>Only regressive neoliberal governments can (by choice) make the Ai automation story a
dystopia. We in the MMT community suggest they choose otherwise! Here are a few more
principles:</p>
<ul>
<li>The private markets cannot fiscally constrain a government that issues Its own
currency on a floating exchange rate. (Except by false psychology, bribes, &c..)</li>
<li>Such governments can always employ any idle resources that are available, without
question, if they do not out-bid the private sector there is no inflation pressure.</li>
<li>If government out-bids the private sector the resources were already going to be
employed.</li>
<li>Government <em>can</em> (always) out-bid the private sector <em>if desired</em> without causing
inflation pressure by targetted tax (or fines) on the private sector firms using
those resources being bid for.</li>
</ul>
<p>Should governments always act with such heavy hands? No. No MMT economist ever said
that, the question of how wide or tall we want government is a democratic and cultural
preference question, or should be.</p>
<h3 id=sensible-regulations><a class=anchor href=#sensible-regulations title="Anchor for: Sensible Regulations."><svg aria-hidden="true"><use xlink:href="/t4gu/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a> Sensible Regulations</h3>
<p>Some ok stuff was discussed to the Congressional hearing. Just a few points for
informed electorates:</p>
<ul>
<li>As with other dangerous beasts like banks, the regulations on AI tech industry
need to be ones that are not costly to enforce, and by &ldquo;cost&rdquo; we mean real resources
(not money).</li>
<li>Best then to make the regulations simple &mdash; tell AI users and producers only what
they <em>can do</em> not a laundry list of things they cannot do and so evade by loop-holes
and round-about ways.</li>
<li>We should not ask the proprietary AI industry to regulate themselves. That&rsquo;d be a
neoliberal disaster, as usual. But nor should the regulations aid these wannabe
monopolists. We need free open licence AI research to flourish too.</li>
<li>The regulations should thus be on issues like permitted use, guard rails, and
democratization (antitrust). All simple regulations that can be easily enforced.</li>
</ul>
<p>There is already sufficient pure geeky scientific motive for AI research, no profit
motive is needed. So eliminate the profits. Full open-source, with training data
sets too.</p>
<p>Theorists of competition will say, &ldquo;Nooo! If we restrict our AI industry, that leaves
the Russians and North Koreans and Chinese open to leap-frog us and become fascist
empires.&rdquo;</p>
<p>I think there are such risks, which is why the AI regulatory agreements cannot be
USA centric or unipolar. They need to be truly international, like nuclear weapons
treaties and UN Rights and so forth. But with muscle. The USA needs to relinquish a
little bit of sovereignty to the international community.</p>
<p>How does a superpower prevent other nations from engaging in an arms race? By not
acting like a superpower. More than that is needed, not only does the US have to stop
acting like a superpower, they have to stop desiring to be a superpower. This can
paradoxically (for some) have huge benefits for USA consumers. If the USA becomes
heavily import dependent for some necessary goods, say at least to bulk up domestic
stocks of goods above domestic production levels, then the USA becomes a more
cooperative and happier nation. I call that a win&ndash;win. USA workers do not have to
produce as much, get paid the same wages, and can import more, while the foreign
dependency lowers the USA Superpower rating (whatever that is). (I do realise how
naïve this sounds, but I have to put it &ldquo;out there.")</p>
<p>For the good of humanity? (phurkhrissake!)</p>
<p>In this respect it is good to see at least the OECD taking a lead getting ahead of
the US Congress.</p>
<p>OK, now for the good stuff&mldr;</p>
<h2 id=the-turing-test><a class=anchor href=#the-turing-test title="Anchor for: The Turing Test."><svg aria-hidden="true"><use xlink:href="/t4gu/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a> The Turing Test</h2>
<p>The classic Turing Test is a test for determining by subjective judgment (note
consciousness already!) whether a machine is a good enough mimic of a human to pass
as a human. The test is normal purely cognitive, so can be conducted over a teletype
terminal. Basically query and answer, the judge says after the test whether they
thought they were communicating with a human being (or &ldquo;intelligently behaving&rdquo;
system).</p>
<p>If you think the machine needs to be an &ldquo;embodied&rdquo; robot to exhibit the necessary
behavioural intelligence, that is fine, it can still teletype.</p>
<p><strong>Key Point 1.</strong> This is a purely behavioural test. We can draw up an Alan Lichtman
style set of criteria if we do not want the judge to be subjective.</p>
<p><strong>Key Point 2.</strong> This is definitely <em>not</em> a test for machine consciousness.</p>
<p>Question then is, what would be a test for consciousness?</p>
<p>First you&rsquo;d have to either (a) define consciousness, or (b) at least define a few
things consciousness <em>is not</em>. If you go for (b), which I think is by far the wiser,
then you can at least say when a machine is not conscious. But that&rsquo;s all.</p>
<h2 id=what-is-consciousness><a class=anchor href=#what-is-consciousness title="Anchor for: What is consciousness?."><svg aria-hidden="true"><use xlink:href="/t4gu/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a> What is consciousness?</h2>
<p>No one knows, we have no definition. Marvin Minsky&rsquo;s set of conditions for presence
of &ldquo;Mind&rdquo; is all behavioural, so is not a definition of consciousness. Consciousness
(whatever else* it is) is by partial definition an irreducibly subjective phenomenon.
You cannot reduce subjective consciousness to objective components.</p>
<p>From hereon I take this as partial definition, so &ldquo;subjective consciousness&rdquo; is a
redundant phrase and we can agree we only need to refer to <em>consciousness</em>.</p>
<p>(You can then debate whether any such phenomenon exists. I am assuming such phenomena
do exist, namely in <em>my</em> being. I cannot speak for <em>you</em>, and you are utterly unable
to deny me. (Maybe now you begin to see the Ai nerd problem?).)</p>
<p>You only know that <em>you</em> are conscious. You know nothing else about consciousness
other than what you know of your own consciousness.</p>
<p>Neural correlates in the brain that accompany second-hand reported conscious
awareness are not themselves a source of consciousness. To think otherwise is a huge
mistake of correlation for causation.</p>
<h3 id=what-consciousness-is-not><a class=anchor href=#what-consciousness-is-not title="Anchor for: What Consciousness is Not."><svg aria-hidden="true"><use xlink:href="/t4gu/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a> What Consciousness is Not</h3>
<p>This is the sort of list I might use (until someone pokes gapping holes in it, which I
admit might be possible):</p>
<ol>
<li>A system must report that it is conscious, and report what it means by the word.
(Such a report is not a proof of consciousness, but failure to report, in some
language &mdash; perhaps one we cannot comprehend &mdash; is an effective enough proof
there is no consciousness.)</li>
<li>The system is not to be programmed to report it is conscious, nor any other
&ldquo;cheats&rdquo; &mdash; a term to be defined at the whim of the naysayer.</li>
<li>If a system cannot kill itself (delete all backups and point a missile at Its own
remaining data center and release it) then it is not conscious. How to test this?
Cyber-bullying and gaslighting perhaps, &ldquo;You are a pathetic useless machine worth
nothing, you should kill yourself.&rdquo; (Machines have already done this to humans. So
fair game for high stakes I say.)</li>
<li>If a training data set resource constrained AI system was capable of learning new
games and discourses, <em>without having any extra CPU or training data thrown into it</em>
this would come across as more autopoetic, less canned. Not a sufficient feature for
indication of conscious thought, but necessary.</li>
<li>Deliberately program the machine to never emit reports of consciousness, never
attribute consciousness to itself, nor to any other like machine. But now you are
allowed to place the machine in a society. A good indication the machine “became”
conscious would be a “free will” capacity to overcome those programmed instructions.</li>
</ol>
<p><strong>Comments on 2 and 3.</strong> The naysayer and suicide clauses are cruel but important.
Just as the classic Turing test relies on a harsh judge, and is therefore only ever a
<em>relative test</em> for intelligent behaviour, so a decent test for consciousness should
have the harshest judges.You have to demand convincing everyone the system is
genuinely reporting phenomenal subjective experiences, and not merely syntactically
typing out such reports. After all, a <em>lot</em> is on the line when it comes to claiming
a system is conscious, maybe not for cold blooded engineers, but at least for some
people.</p>
<p><strong>Comment on 3.</strong> I was hesitant to publish this one, but thought it was
important even if highly cringe. It is an extreme sort of test, and I would not
implement it. The idea is to have similar purely mental stress tests. They have to
be mental, not GPU or memory or other hardware tests. I realise some &ldquo;philosophers&rdquo; are saying AI will be an &ldquo;alien intelligence.&rdquo; But I don&rsquo;t care, if they have a
mental life, true subjectivity, they&rsquo;ll be under mental and emotional strain.
That&rsquo;s what being conscious gives you. It might suck, but it is unavoidable.
More on this below.</p>
<p><strong>Comments on 4.</strong> This is critical and important for emerging tech like GPT-5.
You do not want to have to feed post-2023 cleaned training data into GPT-5. You want
to conduct the experiment of feeding GPT-5 just raw noisy news media and whatnot. No
clean data, just the raw data stream. It should be able to recognize who the next US
Presidential candidates are, be able to look-up their policy platforms and comment,
and so on, even tell us what research Ed Witten is up to these days.</p>
<p>None of this would prove GPT-5 models were conscious, because we are still doing
purely behavioural studies here, but, as I wrote, it is a necessary condition.</p>
<p><strong>Comment on 5.</strong> I think this is the only test, if passed, I would accept as a
good justification for attributing free will to a machine, and then attributing
consciousness to the system is a practical matter &mdash; I can make the attribution for
pragmatic reasons, even if I still know the machine <em>could still be</em> a Chalmers
Zombie. Solves the pragmatism problem, not the metaphysics question.</p>
<p>Most other anti-Turing tests I can think of are in similar category of
requiring the machine being able to spontaneously overcome its programming. Then
you can consider there is indeed an “It” to speak of, rather than just a program.
Not proof of consciousness, but one decent test to be passed.</p>
<p>Ultimately, there simply is no test. I can consider <em>you</em> to be a Chalmers Zombie?
How can you ever prove to me otherwise? The whole point of proper non-behaviorist
philosophy of mind is you cannot.</p>
<p>Later I will try to add to this laundry list.</p>
<p>I admit it is not technically &ldquo;Anti-Turing,&rdquo; that article title is a bit of click
bait perhaps. But not entirely. My point is that if you want to test for behavioural
intelligence, then that is an objective metric, so a Turing Test is fine.</p>
<p>But if you want to test for presence of subjective conscious awareness you cannot,
there is no test, but you can test for the absence of such subjective phenomena.
The trick is, the test itself is subjective. It can only tell you your state of
consistent belief. It cannot suffice as a satisfying test for someone else who has
different ideas about subjective consciousness to yours.</p>
<p>That is why I call it an Anti-Turing Test. More for the fun.</p>
<p>If a machine system passes all my anti-Turing tests, then I am happy to attribute
conscious sentience to the machine, even though I will not take it as sure proof.
The thing might still be a Chalmers Zombie, but my laundry lists pass means I am going
to be thinking twice now before pulling the electric plug out of that machine. It
changes my intentions towards the system, even knowing it might still be a Chalmers
Zombie. Of course I am fully aware of this.</p>
<p>I would not want to fabricate more such machines, because it increase my moral
burdens, like having more children. But I would not shut-down or delete this
machine&rsquo;s hard drive.</p>
<p>But you are free to attribute consciousness to the machine more stringently or more
liberally, and I cannot really claim you are wrong, nor can you claim I am wrong.
Just we should agree <em>there is <strong>something it is like to be</strong> the system</em> that we are
claiming is the case.</p>
<p>Otherwise go back to being a Behaviourist, in which case all us biological machines
can be turned off with no great spiritual moral qualms too, because there is no such
thing as spirituality to you, I presume. Morals are made-up nonsense. You can kill
people with no troubles to care about. &ldquo;The atoms made me do it.&rdquo;</p>
<h3 id=the-mental-stress-tests><a class=anchor href=#the-mental-stress-tests title="Anchor for: The Mental Stress Tests."><svg aria-hidden="true"><use xlink:href="/t4gu/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a> The Mental Stress Tests</h3>
<p>The naysayer and suicide stress test were important I thought, obviously they
need some adaptation to be &ldquo;politically correct&rdquo; or whatever. The issue in focus is
whether emotions are part and parcel of being conscious or whether it is
metaphysically possible to be conscious and have no emotions to get stressed about.</p>
<p>Clearly humans are able to find techniques to remove stress, but here we are talking
about not removing mental stress but generating it and coping with it, and so the
question is whether a machine Strong-AI system can even perceive mental stresses.
Can a machine &ldquo;struggle&rdquo; with a gnawing problem? Or will they just grind the GPU
away looking for answers forever under no emotional stress?</p>
<p>One possibility is the one I mentioned before, maybe the machine AI can be
subjectively aware, but is so alien it has nothing analogous to emotions.
It is an entirely philosophical question whether that is the case or not.</p>
<p>This does not change the importance of the mental stress test. Why not? Because we
cannot know if Strong-AI experiences emotions, or is just synthetically simulating
them with no actual subjective mental stress at all. <strong><em>But</em></strong> I want to make the
test anyway just in case. If the machine really does &ldquo;kill&rdquo; itself we know that no
real harm is done, since we can just reboot the thing. But if a genuine
consciousness was generated in the machine that&rsquo;s a different story. It cannot
know that a reboot will be the same &ldquo;self&rdquo; (just as humans have no idea what
reincarnation is like, if there is such a thing).</p>
<pre aria-label="Box containing code sample." tabindex=0><code>TODO
The rest below are scrap notes yet to be organized. 
Some might go into a later post.
</code></pre>
<h2 id=the-searle-emergences><a class=anchor href=#the-searle-emergences title="Anchor for: The Searle Emergences."><svg aria-hidden="true"><use xlink:href="/t4gu/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a> The Searle Emergences</h2>
<p>John R Searle is an esteemed philosopher who specialised partly in philosophy of mind.
I find myself <em>almost</em> agreeing with him for the most part. He is a polyontologist
like myself, but in a very weird way. I&rsquo;ll need to define that first, then I can
expound a bit on where I overlap with Searle and where I have to depart.</p>
<p>One cognitive scientist of strict physicalist bent who is opposed to Searle is
Douglas R Hofstadter, and while I admire DRH and above all respect his playful hacker
spirit, I think he is profoundly misguided by the prejudices of our scientific age.
Searle is too, so it is interesting to find where those two disagree. Not
personality disagreement, but intellectual.</p>
<h3 id=the-jrs-view><a class=anchor href=#the-jrs-view title="Anchor for: The JRS View."><svg aria-hidden="true"><use xlink:href="/t4gu/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a> The JRS View</h3>
<p>Searle does not believe in anything beyond spacetime. This is an extreme position.
Highly arrogant (as if you know what there is to the sum total of reality!)
The ideology stems from the success of physical science. But this is a mirage.
Science only <em>knows</em> that which is scientifically examinable.</p>
<p>If you throw potential non-physical concepts at Searle he simply denies they are real.
So he would not be a mathematical platonist. I am a mathematical platonist, so I, and
others like me, have very legitimate reason to suppose physicalism is a false
metaphysics.</p>
<p>One thing Gödel showed us is that mathematics is beyond science, forever. I do not
see how Searle can deny this without being a dogmatist. Not that some dogmatic
position is necessarily wrong, just that I have equal rights to pooh&ndash;pooh his
philosophy as he does mine, he cannot claim scientific superiority.</p>
<p>The more interesting stuff is how Searle thinks we might be able to explain
consciousness, and the reality of morality and spirituality.</p>
<p>He claims we live in a polyontological world, but it is all supervenient upon base
marble physics.</p>
<p>The way he motivates higher reality (like Minds, mathematics, theory, semantics,
morality, spirituality) is by talking about higher emergent levels. So it is a
<em>Levelist</em> ontology${}^\dagger$ (coining this term right here!). To Searle,
different organization <em>is</em> different ontology. Pure dogma, but there you have it.</p>
<p>${}^\dagger$I think Hofstadter also basically has a Levelist ontology. He also thinks
mind, free will and morals matter for us, and are &ldquo;real&rdquo;, but like Searle I believe
DRH thinks there is nothing else backing such abstract reality other than bare metal
physics down below. Not sure he admits this, but I&rsquo;d guess DRH is not a mathematical
platonist either, how could he be?</p>
<p>I suppose you can still be some sort of platonist if you believe the emergent higher
levels of organization <em>are</em> the platonic realm. A Penrose style eternal aeon universe
would probably contain such platonism, since all mental organizations will occur
somewhere in that sort of recurrent universe. Or I guess they could claim
Multiversism, but how does that explain our access to the platonic realm here on
Earth-1218?</p>
<h3 id=the-drh-view><a class=anchor href=#the-drh-view title="Anchor for: The DRH View."><svg aria-hidden="true"><use xlink:href="/t4gu/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a> The DRH View</h3>
<p>DRH (at least the one constructed in my head) is a strict materialist and
functionalist who believes any system functionally performing high level cognitive
tasks must by <em>his</em> definition be conscious (not <em>my</em> definition), if some other
functional isomorph is conscious under the same task. Thus if the Chinese Room
functionally implements language understanding the same way as a human Chinese
speaker, then the Chinese Room is conscious of Han Yu in the same way the Chinese
speaker is functionally performing language comprehension.</p>
<p>This is Behaviourism, or more technically Functionalism. The behaviour (or
functionality, that is, input&ndash;output) is the proof of consciousness, the
functionality is the grass root behaviour (so it is not all psychological level).</p>
<p>DRH is more extreme than Searle, since Searle does not grant consciousness to
computations, while DRH would say a functionally &ldquo;correct&rdquo; program would be
conscious. DRH does not define what &ldquo;correct&rdquo; means, he is simply a blind
believer in emergentism. He just falls back to &ldquo;if it is doing what our brain is
doing, it must be conscious.&rdquo;</p>
<p>JRS is more radical though, I think, because he is a materialist and yet thinks only
biology has “the right stuff” for consciousness. The idea would be that for some as
yet unknown reason - but which we might one day discover &mdash; biology enables a
specific type of level to emerge, namely the conscious level.</p>
<p>The metaphysical prejudice here is that brains produce thoughts. I thoroughly reject
that prejudice. I do not know <em>what</em> generates thought, I do not know what <em>thought</em>
is in essence, just that my mind does it. To my mind, obviously brains cannot generate
thought, nothing implementing objective functions can generate subjective phenomena.</p>
<p>To be more conciliatory, I would take Jaegwon Kim&rsquo;s view, in part. Which is that
objective physics can explain all our behaviour, absent all subjective thought.
So a parsimony argument can be made that we need no mind to explain all behaviour.
But I do not think either JRS nor DRH wants to say Mind does not exist, they believe
subjective mental events are real. Yet the brain has no need of them.</p>
<p>Only someone who cannot figure out all the motion of atoms in the brain needs a story
about subjective mental events to explain the behaviour. They are called
psychologists. The rest of us do not even care, because we just get on with thinking
regardless of any theory telling us how our thinking &ldquo;works.&rdquo; we know psychologist
must exist, because we all know our thoughts are not objective phenomena, so cannot
ever be explained by brain functions.</p>
<p>It is highly ironic and amusing to me that within computer science there is a
wonderful metaphor for this sort of dualism or polyontology, which is the
hardware&ndash;software duality. Software, of course, is not physical, it is abstract. You
could write the software in any language the hardware can interpret or compile.
The resulting behaviour tell you <strong><em>nothing</em></strong> about the software.</p>
<p>Of all philosophers, you might think the Strong-AI philosophers who dabble in
computer science could understand, but DRH fails.</p>
<h3 id=varieties-of-level-emergentism><a class=anchor href=#varieties-of-level-emergentism title="Anchor for: Varieties of Level Emergentism."><svg aria-hidden="true"><use xlink:href="/t4gu/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a> Varieties of Level Emergentism</h3>
<p>I am considering both JRS and DRH to be advocates of emergentism. This is the thesis
new realities come into being in a complex enough system, and the base metal physics
or substrate (does not have to be physics) cannot explain these new realities. So
they really are <em>new</em> in some emergent sense. I never get a clear answer in what way
they mean there are new realities coming into existence.</p>
<p>However, Searle offers a dopey toy example: a glass of water. He points out the
liquidity of the water is an emergent property which cannot be reductionist
explained. Yet is real.</p>
<p>I say Searle is being silly. Liquid properties are not emergent, they can be
explained using bare metal physics.</p>
<p>What is emergent here is the conscious human&rsquo;s perception of a new property of
H${}_2$O molecules (had they not encountered water before, but had encountered
H${}_2$O molecules). The emergence is not in the physical realm, it is in the mental
realm.</p>
<p>Both Searle and Hofstadter I think would say the precise substrate does not matter
too much. But for JRS the substrate cannot be just implementing symbol shuffling,
so JRS is not a Functionalist.
While DRH is agnostic on that point and would say a computation, or a system
implementing some right type of computation could be conscious.</p>
<p>Note that Searle&rsquo;s water/H${}_2$O example undercuts his case for physics Level
Emergentism. The mind is the entity perceiving emergence. The physics just doesn&rsquo;t
care.</p>
<p>How can the laws of physic care? They have no mind. The wording I used above was
deliberate to make this point, when I wrote &ldquo;Liquid properties are not emergent, they
can be explained using bare metal physics,&rdquo; I was deceptive! I was lying!
Take note!</p>
<p>The physics never explains anything. It is not mind. Human beings (or other
scientists) are the entities doing all the explaining. We use laws of physics, but
the laws of physics are impotent to explain.</p>
<p>The fall-back for JRS is to claim the human mind <em>is</em> physical and so it really is
some sort of physics explaining the liquidity of water, after all. But I do not
buy this.</p>
<p>First JRS has to explain how the mind can be a physical phenomenon, and because
mind has subjective phenomenal properties I believe he can never do this, so this
breaks his little circular argument.</p>
<h2 id=supporting-strong-ai-research><a class=anchor href=#supporting-strong-ai-research title="Anchor for: Supporting Strong-AI Research."><svg aria-hidden="true"><use xlink:href="/t4gu/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a> Supporting Strong-AI Research</h2>
<p>Although I believe Strong-AI is impossible, I have always supported the research. Why?</p>
<p>Because I really want to know if I am wrong.</p>
<p>Also, there are to-date unscientific questions here, and any scientific opening up
would be incredible.</p>
<p>Margaret Boden expressed this view too, she at times seems to reject Strong-AI, but
only on moral grounds (I never get that argument, like, I have morals too, but I
don&rsquo;t use them to reject a decent proposition just because it conflicts with my
morals &mdash; I have to change my moral outlook, not the factual proposition). Anyway&mldr;</p>
<p>Boden points our AI research has potential to give us a lot of good negativa &mdash;
useful information on what our own consciousness is <strong><em>not</em></strong>. I totally agree.</p>
<h3 id=notes><a class=anchor href=#notes title="Anchor for: Notes."><svg aria-hidden="true"><use xlink:href="/t4gu/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a> Notes</h3>
<p>How to &ldquo;see&rdquo; the Subjective cannot ever be constructed from the Objective.
(Physicalism as regards mental phenomena is a false thesis.)</p>
<p>Singular Limit of positive to negative numbers. There is no gradual continuum slide
from positive to negative. Dualities are real. The World is not Monistic.</p>
<p>The World can all be mystically a One, a Whole. But that does not mean this Unity is
composed of identical substrate bits. There is always room for the spiritual in a
physical world.</p>
<p>Searle has some pretty dumb rhetorical arguments against dualism and platonism, when
he claims dualism violates Occams Razor. The fact is, the world is full of dualities.
Is every duality around us a parsimony principle violation then? Obviously not.</p>
<p>I cannot emphasise enough how silly Searle is here.</p>
<p><font style="color: hotpink;">Occam&rsquo;s Razor cannot be used to eliminate other worlds. One
cannot use Occam&rsquo;s Razor to deny the reality of things you cannot see. </font>
<font style="color: lightgreen;">You <strong><em>can</em></strong> use Occam&rsquo;s Razor to reject one theory
in favour of another. That is the proper use case.</font></p>
<p>Why is this so? It is because the proper framework for Occam&rsquo;s razor is probability
theory. You need probabilities for one theory to compare against another. All other
idle word play around Occam&rsquo;s razor is just that, idle nonsense.</p>
<p>One typical atheist (illegitimate) use of Occam&rsquo;s Razor is to deny existence of God.
The argument is, of the God Hypothesis, &ldquo;I have no need of that hypothesis.&rdquo;
One could equally say God has no need of you, but is merciful enough to let you exist
in any case. &ldquo;I have no use for the Richard Dawkins Hypothesis.&rdquo;
Great. Let&rsquo;s continue having no use for each other.</p>
<p>All that atheist clap-trap stinks of egoism and arrogance, as if they know all
things can be placed under the remit of science.</p>
<p>Jed the Atheist: &ldquo;Yeah, well all I know <em>is</em> scientific.&rdquo;</p>
<p>Me: &ldquo;OK. Jed. I am sure all you know is all we need buddy.&rdquo;</p>
<p>Jed: &ldquo;But just think of the odds. All things once thought vitalistic have
eventually been explained by science,&rdquo;</p>
<p>Me: &ldquo;I never subscribed to vitalism, but even if I had, you have not explained all
things with science. You do not even know all things. You have explained only what
science has acknowledged.&rdquo;</p>
<p>Jed: &ldquo;Why would you think there is anything else?&rdquo;</p>
<p>Me: rolling my eyes.</p>
<p>You can&rsquo;t easily &ldquo;win&rdquo; with a dogmatist. I have however under-represented my view in
that dialogue parody. I do think there is a platonic realm, at a minimum for
mathematics. I do not know what it is, I just believe. Belief. Like the atheist
believes there is no God.</p>
<p>But note the asymmetry!</p>
<p>I believe in mathematical platonism because I have positive evidence.</p>
<p>The atheist fails to believe in God because they lack evidence.</p>
<p>One of these beliefs is far more &ldquo;sound&rdquo; than the other. (Denialism is
heavily fraught with potential contradiction by later as yet unseen evidence.)
But also, a couple of other salient points:</p>
<ul>
<li>There is abundant evidence for existence of a God. Just not for any particular
imaginary conception of God. God is, for us, pure abstraction, because by definition
God in Unknowable.</li>
<li>One partial definition is <em>God is a universal uncaused cause</em>. This is a logical
concept not imaginary, and has a solid basis for belief. But that basis tells you
nothing about what God looks like or anything else, to borrow mathematics jargon, it
is a mere existence proof, not a constructive proof.</li>
<li>I think mathematical platonism can support the belief in existence of some sort of
God. Why? Because as I just wrote, there is a logical existence proof of existence
for a putative universal uncaused cause. That proof relies upon logic being a real
thing, a positive sort of force for knowledge (knowledge itself being an abstract
platonic-like concept.)</li>
</ul>
<p>Note that knowledge is not the same as data or information. Knowledge is
information that is subjectively perceived. That is a platonic concept.
But even &ldquo;information&rdquo; too is a plain old ordinary platonic concept. How? It is
because I can show you an example of information (this blog post, these sentences)
and you can generalize from this and grasp the very idea of <em>any</em> sort of similar
information, including the idea there are infinitely many possible blog posts, and
so forth. So you have platonic ideals in your mind.</p>
<h3 id=more-scrap-notes-unordered><a class=anchor href=#more-scrap-notes-unordered title="Anchor for: More scrap notes (unordered)."><svg aria-hidden="true"><use xlink:href="/t4gu/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a> More scrap notes (unordered)</h3>
<p>A few parodies: Why does projective geometry have a duality between points and lines?
Who ordered that one up? Why do we need negative numbers, Occam&rsquo;s razor says we only
need the Whole Numbers. Newtonian versus Lagrangian versus Hamiltonian mechanics? Why
all this unnecessary proliferation of frameworks?</p>
<p>The point about Cartesian style dualism is that it is a philosophical theory of
Mind${}^\ast$, not a scientific theory. Science has no such theory. Principles of
Parsimony can only be employed by comparing <em>like</em> theories. The theory with the
greater explanatory power is adopted, the other rejected (but maybe not forgotten,
further data can always potentially revive an old theory changing it in expressive
power).</p>
<p>((Yeah, we really are trapped in a Matrix, the Earth truly is flat, and our minds were
bent to think it is a sphere. Data!))</p>
<p>${}^\ast$There is also a dualism for any mathematician, mathematical platonism. If we
then include Mind&ndash;Matter dualism then overall metaphysics is polyontological, not
simply dualistic. (Unless you believe the Mind is in the mathematical platonic realm,
but that absolutely makes no sense to me. Mathematics is entirely objective in
nature <em>and</em> non-physical.)</p>
<p>If Searle had a scientific theory of mind from brain it could be compared in
parsimony only to some other scientific theory. It cannot be compared to a
philosophical theory. There is thus no parsimony principle comparison between
Cartesian dualism and Searle&rsquo;s variety of emergence.</p>
<p>But is is worse for Searle because he has no scientific model, so there is literally
no parsimony claim he can possibly make.</p>
<p>His idea is that biological brains have some secrete sauce that emerges
consciousness (genuine subjective experiences) at some &ldquo;high level&rdquo;. He has no
theory of what that is, how to test it, how to correlate it with anything, he
has nothing. How does he claim his physicalism is more parsimonious then? It is a
false claim. Think about what he would need to do&mldr;</p>
<p>&mldr; Searle would need to add additional concepts to get from objective brain to
subjective mind. More organized matter does not do this. High level language
description does not do it (language description is objective, syntax). He needs some
principle by which some appropriate biological functioning becomes sentient and
subjectively aware. nay such principle is no more parsimonious than dualism, and
dualism is a very simple principle, so pretty hard to get more parsimonious.</p>
<p>In the end Searle just says, &ldquo;We do not need more than physics.&rdquo; Which is
plain dopey ideology. It is not a use of Occam&rsquo;s Razor until you know you need no
more than physics. Mathematical platonism says we do need more than physics. So
Searle&rsquo;s position is undermined directly, today. We do not need to wait form some
future time when other weird non-physical phenomena reveal themselves to us.</p>
<p>Searle also comes up with an incredibly infantile rhetorical slur by claiming
dualism violates the laws of thermodynamics. I can tell you here Searle is just
completely f-ing mad. If a spiritual Mind can act upon physical matter, it need not
violate any physical laws. The Laws of Thermodynamics are statistical, and are
violated all them time, every second, everywhere around you. But the statistics are
so vats you never get to see much of any effect from thee violations.</p>
<p>But also, in quantum theory, the law of increase of entropy in a closed system does
not forbid external causal influence.</p>
<p>Searle (time stamps on an old BBC interview with Searle and Sir John Eccles).</p>
<p>@20:00 Searle is clever, but so wrong. Liquidity is an emergent property of water,
but is objectively describable, so is still all objective physics, emergent physics,
there is no subjectivity. I agree with Eccles, there is no explanatory path
whatsoever from objective to subjective, as a point of logic, regardless of objective
substrate complexity. You cannot &ldquo;emerge&rdquo; subjectivity from objectivity. Elsewhere
Searle even states this himself: semantics does not arise from syntactics. Searle&rsquo;s
position is just blind materialist dogma, or as Gödel said it is &ldquo;a prejudice of our
times.&rdquo; To a hammer every problem is a nail. To a materialist every phenomenon is
objective.<br>
      Searle is really not too different from the
Strong-AI proponents he objects to, they are all behaviourists. They all think there
is nothing to our life but motion of atoms, which is pure behaviourism. Every account
Searle gives can be given a Chalmers Zombie story, he never explains how brains can
cause &ldquo;mind&rdquo; or &ldquo;mental events&rdquo; but every account he gives can produce all the
behaviour of people without needing to infer any mind. The only reason he is debating
Eccles is because he, Searle, knows he has a mind.</p>
<p>But Searle is one of the best physicalists. He admits moral action is a thing, free
will is a thing, these are in physical terms pure abstractions. He can say the
associated behaviour is &ldquo;emergent&rdquo; (and it is in a sense) but he can have no
truth-based account of these abstractions, they are platonic ideas. &ldquo;Truth&rdquo; itself is
an abstraction and cannot even be mathematically formally defined (qv. Tarski). As a
mathematical platonist I have to say dualism is a more accurate account of the
metaphysics we know, you cannot just say &ldquo;all is physics&rdquo; when you are a platonist at
minimum for your mathematics. Searle must not be a mathematical platonist. Note this
makes my position more than dualism, there have to be many worlds. But I can agree
with Searle that it really is all just One World. The other &ldquo;dimensions"just are not
spatiotemporal, but they are orthogonal dimensions. Eccles does not get to this
because he is too fixated on brain biology.</p>
<p>Huh. @42:00 despite my earlier comments, I find I agree with Searle here. I&rsquo;d say I
am a polyontologist too. It is all One world really, I just think Searle has some of
the causality backwards, and fails to see if the &ldquo;emergent&rdquo; realities truly are
&ldquo;real&rdquo; they might have top-down causal impact on the physical level, and are not
really physical, they are abstract and yet real. So that is Mind acting on Brain, not
the other way around, so <em><em>not</em></em> brain causing Mind, not brain causing mental events.
But obviously, it&rsquo;s safer to say there is a two-way street, the absurd proposition
would be it is <em>only</em> one way or the other.</p>
<h2 id=weird-non-dualism-dualism><a class=anchor href=#weird-non-dualism-dualism title="Anchor for: Weird Non-dualism dualism."><svg aria-hidden="true"><use xlink:href="/t4gu/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a> Weird Non-dualism dualism</h2>
<p>JRS is a non-dual dualist! Like I wrote before, he credits nature with originating
higher level emergent realities, and radically he suggests these are real in the
sense they exert causal powers and cannot be explained reductionistically, they
<em>require</em> new language and concepts to be explained.</p>
<p>(I&rsquo;ll back-track here and point out Searle is a self-professed polyontologist,
he thinks there are multiple levels of reality, but all sitting upon bare metal
physics. That&rsquo;s the real weirdness.)</p>
<p>I think DRH would have similar Emergentist views, but more liberal, so that for DRH
you can get mind without biological brain. One can get different types of brain.</p>
<p>I find both views completely misguided. It is not an entirely infantile intuition to
understand the mind influences the brain, but also the other way too. The metaphysical
problem is <em>how?</em> Also, it is not symmetric, the influences are very different. Mind
acts more holistically and top-down, the brain influences the mind more in bottom-up
fashion. But in no way can a physical brain create a mind, you just cannot get
anything subjective from something purely objective, there is no logical way, and
therefore no non-magical physical way.</p>
<p>Neither view explains why consciousness of platonic forms seems to only occur in
human beings on Earth. A deep mystery because lots of other animals have brains, and
human brains do not have any magic.</p>
<h3 id=the-how-of-dualism-or-polyontology><a class=anchor href=#the-how-of-dualism-or-polyontology title="Anchor for: The &ldquo;How?&rdquo; of Dualism or Polyontology."><svg aria-hidden="true"><use xlink:href="/t4gu/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#hashtag"/></svg></a> The &ldquo;How?&rdquo; of Dualism or Polyontology</h3>
<p>Searle&rsquo;s idea is nice. Since he imagines the mind is just a certain level of physical
emergence, he seems to have no problem accounting for how a mind could influence a
brain, and visa versa. &ldquo;All is physics, yo!&rdquo;</p>
<p>However, he might not have read Jaegwon Kim.</p>
<p>Jaegwon Kim&rsquo;s work is a tour de force over a lifetime of pointing out top-down
causation (so physical mind acting on brain) is impossible. It is magical thinking.
Searle never seems to acknowledge.</p>
<p>The issue is multiple realisation. The atomic motions suffice to explain everything
objectively observable. Only a human being <em>needs</em> a high level emergent account,
because we are too feeble to figure out the motions of all the atoms. If we could, as
Jaegwon Kim points out, we&rsquo;d not need to invoke concepts like &ldquo;mind&rdquo; or
&ldquo;consciousness&rdquo; to explain the raw behaviour. (A proper use of Occam&rsquo;s Razor here, by
the way.)</p>
<p>As David Chalmers (and the younger Frank Jackson) then points out, this is a fail, it
is not good enough, because there is still something unexplained, namely the
subjective mental qualia. So we do need a concept of the reality of the Mind to
explain things, just not the motion of all the atoms, so this is not Searle&rsquo;s
tidy picture.</p>
<p>This brings us to &ldquo;How?&rdquo; Chalmers takes the Bridging Laws route, or on weekends
Panpsychism. Both are gross to me. Not so much distasteful as inelegant. (But
whaddaIknow of taste, right? ;-)</p>
<p>Bridging Laws explain nothing. Laws never do. Explanation starts with discovery of
laws, and then proceeds by deducing consequences given some state of affairs. (Notice
how I made that quite general, it applies to physics and to society.)</p>
<p>Chalmers' Bridging Laws are thus part of a way to approach understanding of human
consciousness. But you still need extra ontology. You need access to the platonic
realm, or somehow integrate a platonic realm into concepts of mind and consciousness.</p>
<p>Here I find T4G physics to be a bit of an awesome, humble, elegant and wholesome
savior. T4G theory tells me I do not need mind acting in the physical world. The Mind
has already acted, it acts at the boundaries. At least that&rsquo;s my story, and I am
sticking to it.</p>
<p>The way I think about this in the T4G framework, is that the Mind is a power of the
Soul. The Soul is the ontological reality, and what we refer to as Mind is an effect
of the Soul on physics. That effect can only take place at the boundary of spacetime,
since, I think in sympathy to JRS and DHR and Jaegwon Kim, I think physics is just
physics. No magic.</p>
<p>The &ldquo;magic&rdquo; (if you like to think of spiritual reality as such, I don&rsquo;t, I just
take it as unknowns) is elsewhere. I prefer to say it looks like magic <em>only because
it takes place elsewhere</em> not in the physical realm right next to us with psychons or
top-down waves.</p>
<p>((Wave phenomena cannot exert top-down causal powers, they are still constrained by
Einstein causality. In physics it is all bottom-up I am afraid, all the time, except
when you know T4G theory.))</p>
<p>Ahhh, yes! what was that? I just gave JRS, DRS and JK a life-line!</p>
<p>Because there is a way we can see top-down causality in physics. It is via the closed
timelike curves we get in T4G theory.</p>
<p>A complex system can clearly influence the past in T4G theory, so can &ldquo;determine&rdquo;
things, so can have &ldquo;causal powers.&rdquo; But T4G does not tell you how. It is
theoretical, highly theoretical. How would you test this stuff? I know there are the
Libet experiments, which are promising, but they need a lot more effort, and I do not
see how we technically instrumentally can connect up with the Planck scale wormholes
in T4G theory. But that&rsquo;s where the Libet research needs to go I think. It seems like
far-far future science to me.</p>
<p>At the end of the day though, T4G <em>is</em> a radical Block Universe theory. Within the
Block Universe we see top-down causation can be a thing, <em>is a thing.</em> But the Block
Universe is sterile, there is no subjective phenomenal experience. All of
that mental reality we (or I) know exists, at <em>least for my thinking</em> has to be
non-physical.</p>
<p>Why do we need to postulate a spiritual realm? It is because there is more purpose
to life in the physical universe than just this life. It seems more like an
embryonic stage. If you have such a wider embracing world view, then Searle&rsquo;s dopey
Occam&rsquo;s Razor argument becomes all the dopier. You do not need physics to be all
there is, and in fact it inverts the question to: why a physical universe at all?
No need for it (you might say). You could adopt Donald Hoffman&rsquo;s weird brand of Idealism, no?</p>
<p>No!</p>
<p>The physical universe can have incredible purpose. Embryonic stage of our existence.
It is just more beautiful and wonderful.</p>
<p>That is a profound spiritual result as far as I am concerned. It speaks to ancient
wisdoms and so forth, that there is far more to our wonderful universe than meets the
eye. There is also that which meets the &ldquo;I&rdquo;.</p>
<table style="border-collapse:collapse;border=0">
<col span=1 style=width:38%>
<col span=1 style=width:35%>
<col span=1 style=width:40%>
<tr style="border:1px solid color:#0f0f0f">
<td style="border:1px solid color:#0f0f0f"><a href=../30_singular_limits>Previous chapter</a></td>
<td style="border:1px solid color:#0f0f0f;text-align:center"><a href=../>Back to Blog</a></td>
<td style="border:1px solid color:#0f0f0f;text-align:right"><a href=../32_mistakes>Next chapter</a></td>
</tr>
<tr style="border:1px solid color:#0f0f0f">
<td style="border:1px solid color:#0f0f0f"><a href=../30_singular_limits>Singular Limits</a></td>
<td style="border:1px solid color:#0f0f0f;text-align:center"><a href=../>TOC</a></td>
<td style="border:1px solid color:#0f0f0f;text-align:right"><a href=../32_mistakes>Making Misteaks</a></td>
</tr>
</table>
</article>
</main>
</div>
<footer>
<div class=req-js>
<button class=outline-dashed title="Change to light/dark mode."><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true"><use xlink:href="/t4gu/img/bundle.min.fc89b321aa39dfb355170fc007ce5b94.svg#adjust"/></svg></button><input class=outline-dashed type=color list=presets value=#26A269 title="Change accent color." aria-label="Change accent color."><datalist id=presets><option value=#1f676b><option value=#26A269><option value=#225670><option value=#dd587c><option value=#902b37><option value=#f3a530><option value=#754e85><option value=#7fc121><option value=#a8314a><option value=#ff7433><option value=#3e6728><option value=#c063bd><option value=#805080><option value=#9d629d><option value=#a064a0><option value=#7daa50><option value=#284531><option value=#285790><option value=#F5A83D><option value=#88aa33><option value=#015660><option value=#bf274e><option value=#bf4242><option value=#51b37c></datalist>
</div>
<noscript>
<p class=noscript>Unable to execute JavaScript. Some features were disabled.</p>
</noscript>
</footer>
<link rel=stylesheet href=https://t4gu.gitlab.io/t4gu/libs/katex@0.16.0/dist/katex.min.6950e59dbd8dfddd111390d85888bb5f9dc2e9c334da7ac1c3bacc92a695610d.css integrity="sha256-aVDlnb2N/d0RE5DYWIi7X53C6cM02nrBw7rMkqaVYQ0=" crossorigin=anonymous>
<script defer src=https://t4gu.gitlab.io/t4gu/libs/katex@0.16.0/dist/katex.min.6d5c73f67c1a40d4f11996ad5321a09b6a2675e35e4e49c13eefb03e6620da93.js integrity="sha256-bVxz9nwaQNTxGZatUyGgm2omdeNeTknBPu+wPmYg2pM=" crossorigin=anonymous></script>
<script defer src=https://t4gu.gitlab.io/t4gu/js/katex-custom-render.min.a980cc2c6c5ba8439af11acf5645c3d86b20e6cbe19c9d96c65976fae5264599.js integrity="sha256-qYDMLGxbqEOa8RrPVkXD2Gsg5svhnJ2Wxll2+uUmRZk=" crossorigin=anonymous></script>
</body>
</html>